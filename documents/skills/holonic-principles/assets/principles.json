{"schema":"cac.holonic_bundle.v1","schema_version":"1.0.0","kind":"holonic.bundle","meta":{"stable_id":"dcp://apm2.agents/holon/selector@1","classification":"PUBLIC","created_at":"2026-02-04T00:00:00Z"},"payload":{"version":"1.0.0","principle_count":99,"principles":[{"id":1,"name":"landauer-s-principle","title":"Landauer\u2019s principle: erasure costs energy, so \u201cfree compute\u201d is fake","formal":"any logically irreversible bit erase dissipates at least\n[\nE_{\\min} = kT \\ln 2 \\quad \\text{joules per bit}\n]\nwhere (k) is Boltzmann\u2019s constant and (T) is temperature. Real systems are orders of magnitude above this bound, but the direction is immutable: *compute \u2192 heat \u2192 limits*.","apm2_mapping":"treat **token budgets**, **tool budgets**, and **artifact bytes** not as \u201cproduct limits\u201d but as **thermodynamic proxies**: every extra tool call and every extra token is irrecoverable physical work somewhere. APM2 already encodes this as session budgets (`apm2_core::budget`) and ContextPack budgets (CAC). The missing step is to express *energy/cost* as a first\u2011class budget dimension and bind it to receipts (so \u201cwe spent X\u201d is auditable, not narrative).","connections":[8,27,63]},{"id":2,"name":"roofline-model","title":"Roofline model: performance is min(compute peak, bandwidth peak \u00d7 arithmetic intensity)","formal":"[\nP = \\min(P_{\\text{peak}}, ; BW_{\\text{peak}} \\cdot AI)\n]\nwhere (AI = \\frac{\\text{FLOPs}}{\\text{bytes moved}}). This is the cleanest \u201cwhy is my code slow?\u201d litmus test.","apm2_mapping":"APM2\u2019s *dominant* workload is often \u201cmove bytes and validate them\u201d (ledger/event replay, CAS retrieval, schema validation, policy eval), which is usually **bandwidth/latency bound**, not FLOP bound. That means performance wins come from: (a) fewer bytes (principle 5), (b) fewer round\u2011trips (13), (c) deterministic compression (66), and (d) locality (20\u201322). Treat \u201cbytes moved per verified progress\u201d as a first\u2011class metric in the observability plane.","connections":[3,4,5,9,66]},{"id":3,"name":"arithmetic-intensity-predicts-compute-bound-vs-bandwidth-bound-regimes","title":"Arithmetic intensity predicts compute\u2011bound vs bandwidth\u2011bound regimes","formal":"(AI) is the slope of the bandwidth line in roofline. If your algorithm\u2019s (AI) is low, adding more compute doesn\u2019t help.","apm2_mapping":"translate (AI) into *cognitive* and *governance* terms:\n\n* **Data\u2011plane AI:** validation and hashing are memory bound; optimize for fewer passes and smaller payloads (13).\n* **Control\u2011plane AI:** \u201cverification work per byte of evidence\u201d is what matters. Evidence must be compact but sufficient (92).\n  If a gate requires fetching huge context, it is low \u201cverification intensity\u201d and will dominate budgets. This is exactly why APM2 pushes ContextPacks and content hashes: ship **references** not blobs.","connections":[4,5,45,92,97]},{"id":4,"name":"gemm-tiling-blocking","title":"GEMM tiling/blocking: locality engineering is *the* performance lever","formal":"","apm2_mapping":"","connections":[]},{"id":5,"name":"communication-avoiding-algorithms","title":"Communication\u2011avoiding algorithms: minimize bytes moved per unit of progress","formal":"in distributed systems, cost is dominated by communication (C) not compute (W). Many optimal algorithms minimize (C) even if (W) rises.","apm2_mapping":"APM2 already does the canonical comm\u2011avoid trick: **CAS + hashes**. Tool protocol passes prompt hashes and artifact hashes rather than raw bodies; the ledger stores small event payloads and references. Extend this principle to **authority**: minimize *capability movement* too\u2014delegation should be rare, attenuated, and auditable.","connections":[38,45,46,47,53]},{"id":6,"name":"amdahl-gustafson","title":"Amdahl + Gustafson: small serial paths dominate at scale","formal":"Amdahl:\n[\nS(N)=\\frac{1}{(1-p)+p/N}\n]\nGustafson: scaled speedup grows with problem size:\n[\nS(N)=N-(1-p)(N-1)\n]","apm2_mapping":"APM2\u2019s serial fraction is the **control plane**: policy decisions, lease issuance, ledger append, gate adjudication. If those are slow or flaky, the whole holarchy stalls. Hence: keep control-plane state minimal (49), deterministic (59), and always-on. Anything expensive must move to the data plane with receipts.","connections":[49,59,63]},{"id":7,"name":"work-span-model","title":"Work\u2013span model: optimize critical path under verification constraints","formal":"(T_p \\ge \\max(W/p,; S)), where (W) = total work, (S) = span (critical path).","apm2_mapping":"APM2\u2019s \u201cwork\u201d is not just code changes; it\u2019s **verified progress**. Verification adds edges to the DAG, increasing span. So decomposition must explicitly minimize **verification span**, not just implementation span. The work module already models parent_work_ids and transitions; use that DAG to compute span and to choose parallelization that doesn\u2019t explode evidence dependencies.","connections":[8,9,95]},{"id":8,"name":"batching","title":"Batching: amortize overhead but trade for tail latency","formal":"batching lowers per-request fixed cost, increases waiting time. Queueing theory: batching inflates (W) even if service time drops.","apm2_mapping":"APM2 already batches ledger reads in reducer replay and rate-limits/paces pulses. But you need explicit **batch policies by risk tier**: high-risk actions (deploy, key ops) should *not* wait for throughput optimization. Low-risk telemetry can batch aggressively. Encode these policies as part of resource governance and gate scheduling.","connections":[9,26,27,28,29,94]},{"id":9,"name":"tail-latency-is-usually-queueing-not-kernel-speed","title":"Tail latency is usually queueing, not kernel speed","formal":"p99 latency explodes when utilization (\\rho \\to 1). In M/M/1, (W = \\frac{1}{\\mu-\\lambda}) (diverges as (\\lambda \\uparrow \\mu)).","apm2_mapping":"the daemon\u2019s HEF pulse plane already includes queue depth limits and drop policy\u2014this is the correct instinct: **bound queues, drop low-priority first**. Extend this to tool execution, gate evaluation, and evidence publication: every subsystem needs backpressure and bounded in-flight work, or you will get cascading failure.","connections":[25,26,27,53,54,55,56,66]},{"id":10,"name":"stochastic-rounding-mixed-precision","title":"Stochastic rounding + mixed precision: trade numeric noise for throughput","formal":"stochastic rounding yields unbiased quantization; mixed precision uses FP16/BF16 with occasional FP32 accumulation to control error.","apm2_mapping":"treat *every approximate agent decision* (model outputs, heuristic routing) as \u201cmixed precision.\u201d The system must define explicit **error budgets** and **fallback triggers**: when uncertainty rises, escalate to higher precision (more context, better model, more verification). Encode these as policies keyed to risk tiers and gate outcomes.","connections":[63,76,77,78,79,94]},{"id":11,"name":"quantization-aware-training-inference","title":"Quantization-aware training/inference: \u201ccapability\u201d depends on deployment format","formal":"accuracy is a function of quantization scheme (q(\\cdot)), hardware kernels, and calibration.","apm2_mapping":"model selection in APM2 cannot be \u201cmodel name only.\u201d It must be \u201cmodel \u00d7 runtime profile \u00d7 context budget \u00d7 reliability constraints.\u201d This is why a model_router exists: route based on SLOs, cost, and risk. Store **capability profiles** as versioned artifacts, and treat them as inputs to scheduling and policy.","connections":[17,18,63,66]},{"id":12,"name":"structured-sparsity-is-only-real-if-hardware-exploits-it","title":"Structured sparsity is only real if hardware exploits it","formal":"sparsity only yields speedup if it improves effective bandwidth/compute; otherwise it\u2019s overhead.","apm2_mapping":"the analogy is \u201cstructured governance.\u201d Adding more gates and policies is only beneficial if enforcement is cheap and predictable; otherwise governance becomes its own DoS. Therefore: **compile governance** (policy-as-code, schema validation) into fast monotone checks and cache results by content hash (45).","connections":[59,71,93]},{"id":13,"name":"kernel-fusion","title":"Kernel fusion: reduce memory round-trips","formal":"fuse ops to avoid writing intermediate tensors to memory.","apm2_mapping":"in APM2, \u201cfusion\u201d means: avoid multi-step parse\u2192validate\u2192transform passes over the same data. Canonicalize once, validate once, hash once, store once, then only ship references. Evidence and CAC pipelines already push in this direction. Make it explicit: one pass from untrusted input to canonical form + receipt.","connections":[45,46,47,90]},{"id":14,"name":"io-aware-attention","title":"IO-aware attention: long-context inference is memory traffic dominated","formal":"attention complexity and bandwidth dominate as context grows; KV reads/writes dominate decode.","apm2_mapping":"this is why **ContextPack budgets** matter. Long context is a systems problem: caching, invalidation, and eviction are required (15, 97). In APM2, \u201clong context\u201d is mostly *retrieved documents + evidence + diffs*. Treat that as cacheable content-addressed artifacts with explicit TTL and version bindings.","connections":[15,96,97]},{"id":15,"name":"kv-cache-is-a-physical-resource-budget-it-like-os-pages","title":"KV-cache is a physical resource; budget it like OS pages","formal":"KV-cache capacity (M) limits concurrent sequences; eviction policy affects recomputation.","apm2_mapping":"**agent working memory is KV-cache**. ContextPacks are effectively \u201cpinned pages.\u201d Budget token/context per lease and per risk class. If a task requires more context than allowed, that\u2019s a *context defect* (pack miss) and should be logged as such, not worked around by \u201cjust retrieve more.\u201d","connections":[3,4,5,96,97]},{"id":16,"name":"speculative-decoding","title":"Speculative decoding: trade extra compute for latency by \u201cbetting\u201d on tokens","formal":"speculative decoding uses a draft model; accept if verifier agrees, otherwise rollback.","apm2_mapping":"speculative decoding is **optimistic execution + verification**. That\u2019s the APM2 pattern in general: agents propose actions; gates verify; ledger commits. The key is rollback safety: all side effects must be idempotent and capability-scoped (48, 38). Use speculation for low-risk steps (formatting, lint fixes), but require receipts before promotion.","connections":[48,63,94]},{"id":17,"name":"continuous-batching","title":"Continuous batching: separate prefill from decode; schedule on token throughput","formal":"throughput is tokens/sec, not requests/sec; prefill is parallelizable, decode is sequential.","apm2_mapping":"for inference, the scheduler should think in **token budget burn rate**. For the control plane, think in **event throughput** and **receipt throughput**, not \u201cnumber of sessions.\u201d Track costs per stage (prefill/context compilation, tool actuation, verification) and allocate capacity accordingly.","connections":[8,9,27]},{"id":18,"name":"parallelism-modes-are-topology-optimization-not-a-toggle","title":"Parallelism modes are topology optimization, not a toggle","formal":"data/tensor/pipeline/expert parallelism trade latency, bandwidth, memory, synchronization.","apm2_mapping":"\u201cwhere an agent runs\u201d is similarly a topology problem: running a holon near its data (repo, ledger shard, evidence store) matters more than raw compute. This is roofline applied to *networked cognition.* Model the placement problem as constrained optimization (75) under failure domains (62).","connections":[19,24,62,75]},{"id":19,"name":"collectives-are-topology-sensitive-placement-must-match-fabric","title":"Collectives are topology-sensitive; placement must match fabric","formal":"all-reduce cost depends on link bandwidth/latency and algorithm (ring/tree).","apm2_mapping":"in a distributed APM2, consensus replication and anti-entropy are your collectives. Design replication and witness protocols to minimize cross\u2011partition chatter and to align with network topology. The consensus module already encodes bounded jitter and fixed-size frames\u2014extend with topology-aware peer selection and batching.","connections":[24,25,49]},{"id":20,"name":"numa-locality","title":"NUMA locality: \u201cone rack\u201d isn\u2019t uniform memory","formal":"remote NUMA accesses cost more; thread/page placement matters.","apm2_mapping":"the analog is \u201cone trust domain isn\u2019t uniform authority.\u201d Inside a rack, some executors should still be isolated (side channels, secrets). Pin high\u2011risk workloads to isolated domains (35). Also pin data-plane heavy tasks near their storage.","connections":[34,35,55]},{"id":21,"name":"memory-tiers-hbm-dram-ssd-object-store","title":"Memory tiers (HBM/DRAM/SSD/object store): map cognitive tiers explicitly","formal":"latency/cost hierarchy demands explicit placement and eviction.","apm2_mapping":"APM2 already has:\n\n* **working context** (episode/session),\n* **episodic ledger** (append-only events),\n* **artifacts/evidence** (CAS),\n* and likely a **semantic index** (future).\n  Make tiering explicit: working memory is lossy; ledger+CAS are authoritative. Anything you can\u2019t replay from ledger+CAS is a design defect.","connections":[45,46,47,96]},{"id":22,"name":"pcie-host-device-transfers-are-expensive","title":"PCIe host\u2194device transfers are expensive: treat boundaries as quota\u2019d interfaces","formal":"crossing bus boundaries costs latency and bandwidth; avoid chatty transfers.","apm2_mapping":"\u201cboundary\u201d = **tool call**. Every tool call crosses a trust boundary and should carry explicit budgets, schemas, and receipts. APM2 does this with protobuf tool requests, validation, policy evaluation, and budget consumption accounting. Don\u2019t bypass that boundary \u201cfor convenience.\u201d","connections":[38,90,91]},{"id":23,"name":"rdma-kernel-bypass-io","title":"RDMA/kernel-bypass IO: higher performance, more footguns","formal":"bypassing kernel reduces overhead but removes safety rails; correctness burden shifts to user code.","apm2_mapping":"any \u201cfast path\u201d (direct executor access, privileged tools, bypassed gates) must be wrapped in **typed, verified libraries** and restricted to high-trust actors. Otherwise you just created a privileged injection surface.","connections":[33,38,89,90,91]},{"id":24,"name":"network-topology-shapes-bisection-bandwidth-partition-to-minimize-chatter","title":"Network topology shapes bisection bandwidth; partition to minimize chatter","formal":"cost of communication depends on graph cut size; minimize edge cut for task graph.","apm2_mapping":"treat the **work DAG** as a graph partitioning problem: co-locate tightly-coupled work items (shared context packs, shared artifacts) and isolate weakly coupled ones. This reduces both bandwidth and *attack surface* (bulkheads).","connections":[55,95]},{"id":25,"name":"congestion-control-aqm-decide-whether-the-system-collapses-under-load","title":"Congestion control + AQM decide whether the system collapses under load","formal":"queue discipline (RED/CoDel) and pacing prevent bufferbloat and collapse.","apm2_mapping":"HEF resource governance is AQM: bounded queues, rate limits, drop priority. Extend the same design to: tool execution pools, ledger append contention, CAS retrieval, and CI import. The measurable goal is stability under load (no oscillation, bounded tail latency).","connections":[9,26,27,28,29,53]},{"id":26,"name":"pacing-jitter-control-deadline-scheduling-separate-p50-from-p99","title":"Pacing + jitter control + deadline scheduling separate p50 from p99","formal":"jitter adds variance; EDF (earliest deadline first) can be optimal under certain assumptions.","apm2_mapping":"assign **SLO and deadline semantics** to actions: tool calls, gate evaluations, replication messages. The consensus module already uses bounded jitter constants; extend to scheduling policies per topic class (ledger head vs episode IO).","connections":[25,63,64,65,66]},{"id":27,"name":"little-s-law","title":"Little\u2019s law: (L = \\lambda W) makes autoscaling/admission math explicit","formal":"average number in system (L) equals arrival rate (\\lambda) times average time in system (W).","apm2_mapping":"treat \u201cactive work items,\u201d \u201cin-flight tool calls,\u201d and \u201cqueued pulses\u201d as (L). If you can measure (\\lambda) (arrivals) and want bounded (W) (latency), then you must enforce admission control (53) or increase capacity. \u201cHeuristic autoscaling\u201d without Little\u2019s law is basically superstition.","connections":[8,9,53]},{"id":28,"name":"model-predictive-control-mpc","title":"Model predictive control (MPC): stability under constraints/delays","formal":"optimize control sequence (u_{t:t+H}) over horizon (H) subject to dynamics (x_{t+1}=f(x_t,u_t)) and constraints.","apm2_mapping":"governance and autoscaling are controllers. The \u201cplant\u201d is: queue lengths, token burn, tool pool occupancy, ledger growth. MPC suggests: don\u2019t react to instantaneous spikes; plan with constraints (budgets, risk tiers) and with known delays (CI latency, network partitions). Encode the plant model and constraints in policies, not ad-hoc code.","connections":[29,63]},{"id":29,"name":"feedback-loops-oscillate-under-delayed-noisy-observation","title":"Feedback loops oscillate under delayed/noisy observation","formal":"delayed feedback can destabilize proportional controllers; filtering and hysteresis are standard mitigations.","apm2_mapping":"telemetry is a control input. If you react to noisy error rates with immediate throttling/spawning, you will oscillate. APM2 should treat telemetry ingestion and aggregation as part of the stability story: risk-aware sampling (66), smoothing, hysteresis, and \u201chold-down timers\u201d for policy changes.","connections":[66,67]},{"id":30,"name":"time-synchronization-limits-tracing-and-ordering-tolerate-skew","title":"Time synchronization limits tracing and ordering; tolerate skew","formal":"no global time; clocks drift; ordering must be logical (Lamport/HLC/vector clocks).","apm2_mapping":"APM2 already embeds **HLC fields** in ledger events and uses **tick-based time (HTF)** for lease expiry. That is the correct direction: avoid \u201cwall clock as authority.\u201d For observability and replay, bind events by sequence/causality, not timestamps.","connections":[50,65]},{"id":31,"name":"record-replay-debugging","title":"Record/replay debugging: capture minimal deterministic traces","formal":"reproduce by recording nondeterministic inputs and replaying under deterministic execution.","apm2_mapping":"the ledger + CAS is the natural record/replay substrate. The missing piece is **tool determinism receipts**: store tool request, tool response hash, environment snapshot hash (hermeticity), and attach to work/gate receipts. If an action can\u2019t be replayed from receipts, it is not fully verified.","connections":[58,92,95]},{"id":32,"name":"os-scheduler-cgroups-are-the-last-line-of-single-host-isolation","title":"OS scheduler + cgroups are the last line of single-host isolation","formal":"kernel primitives enforce CPU/mem/IO quotas; without them, \u201cpolicy\u201d is advisory.","apm2_mapping":"APM2\u2019s policy engine must compile down to kernel-enforced constraints for high-risk executors: cgroups, namespaces, seccomp. The \u201cpolicy said no network\u201d is meaningless if the process can still open sockets.","connections":[91]},{"id":33,"name":"ebpf","title":"eBPF: programmable measurement/enforcement close to substrate","formal":"attach programs at kernel hook points for observability and policy.","apm2_mapping":"eBPF is an ideal *observability amplifier* for APM2: you can measure per-tool syscall patterns, detect unexpected egress, and feed that into gates as receipts. Treat this as \u201chardware telemetry\u201d for the governance controller.","connections":[65,66,91,92]},{"id":34,"name":"containers-share-a-kernel-high-risk-executors-may-need-microvms","title":"Containers share a kernel; high-risk executors may need microVMs","formal":"container isolation is weaker than VM isolation; kernel bugs and side channels remain.","apm2_mapping":"default should be: low-risk tools in containers; higher-risk actions in microVMs with stricter boundaries. Map \u201crisk tier\u201d directly to isolation class. If you don\u2019t, prompt injection becomes \u201cget root in shared kernel.\u201d","connections":[35,91,94]},{"id":35,"name":"side-channels-are-unavoidable-separate-secrets-by-isolation-class-and-hardware-domain","title":"Side channels are unavoidable; separate secrets by isolation class and hardware domain","formal":"timing/cache/power leak information even with perfect software.","apm2_mapping":"treat \u201csecrets\u201d and \u201chigh-risk workloads\u201d as physically separate. Don\u2019t put key material in the same host as adversarial workloads. In APM2 terms: capability minting, signing keys, and policy bundles must live in hardened enclaves/domains.","connections":[36,37,38,39,40,41,42,43]},{"id":36,"name":"secure-boot-measured-boot","title":"Secure boot + measured boot: bind software state to hardware roots of trust","formal":"a chain of trust extends from hardware (TPM) through bootloader to OS.","apm2_mapping":"to scale beyond one developer machine, APM2 needs executor attestation. Otherwise your \u201ckernel\u201d can be replaced and still claim compliance.","connections":[37,44]},{"id":37,"name":"remote-attestation","title":"Remote attestation: trust becomes a verifiable claim","formal":"prove to a verifier that the prover is running approved code/config, typically using TPM quotes or enclave attestation.","apm2_mapping":"any node receiving authority (capabilities, keys, deployment power) must present attestation *before* delegation. This aligns with APM2\u2019s \u201cfail-closed\u201d posture: if attestation missing/unverifiable, deny.","connections":[38,93,94]},{"id":38,"name":"capability-based-security","title":"Capability-based security: prevent ambient authority via attenuable tokens","formal":"authority is represented explicitly as a capability object; delegation is attenuation:\n[\ncap' \\preceq cap\n]\nin a partial order of privilege.","apm2_mapping":"APM2 already implements OCAP in the lease/capability system: scope hashes, budgets, expiry, delegation depth, signatures. This is the primary defense against confused-deputy prompt injection. Treat capability attenuation as a *lattice* (71): operations should be monotone (only reduce privileges).","connections":[71,89,90,91]},{"id":39,"name":"zero-trust-service-identity","title":"Zero-trust service identity: authenticate/authorize every hop","formal":"assume hostile networks; use strong identities and per-request authorization.","apm2_mapping":"the consensus layer uses mutual TLS; extend this to all internal planes, including pulse/HEF distribution and any external adapters. \u201cInside the rack\u201d is not a boundary.","connections":[40]},{"id":40,"name":"mtls-automated-rotation","title":"mTLS + automated rotation: table stakes","formal":"long-lived certificates become liabilities; rotation must be automated.","apm2_mapping":"bake cert lifecycle into the system as an autonomous subsystem. If rotation requires humans, it will fail under pressure. Integrate rotation events into ledger for auditability.","connections":[43,44]},{"id":41,"name":"post-quantum-migration-requires-crypto-agility-and-hybrid-modes","title":"Post-quantum migration requires crypto agility and hybrid modes","formal":"plan for hybrid key exchange/signatures: classical + PQ, with version negotiation and downgrade protection.","apm2_mapping":"APM2\u2019s signing/verification and identity protocols should be versioned and negotiation\u2011safe now, not after you ship global. Treat crypto algorithms as policy-configured primitives with signed policy bundles.","connections":[93]},{"id":42,"name":"harvest-now-decrypt-later","title":"Harvest-now-decrypt-later: confidentiality lifetimes matter","formal":"adversary records ciphertext now, decrypts later when capabilities improve.","apm2_mapping":"the evidence store and telemetry are extremely sensitive. Classification and retention (already present in evidence module) are non-negotiable: store only what you must, for as short as you can, and encrypt according to confidentiality lifetime.","connections":[43,66]},{"id":43,"name":"secrets-should-be-short-lived-and-scoped-prefer-secretless-jit-credentials","title":"Secrets should be short-lived and scoped; prefer \u201csecretless\u201d JIT credentials","formal":"blast radius scales with secret lifetime and scope.","apm2_mapping":"capabilities and session tokens should be time-bounded; tooling should fetch JIT credentials rather than storing secrets in context. Every secret that enters a prompt is a future incident.","connections":[89,91]},{"id":44,"name":"supply-chain-provenance","title":"Supply-chain provenance: promotion is graph verification, not a trust leap","formal":"verify build graph integrity: source \u2192 build \u2192 artifact \u2192 deploy, with signed attestations.","apm2_mapping":"APM2 already wants evidence bundles; extend to full supply chain: deterministic builds (58), provenance attestations, and content-addressed artifact manifests. Promotion should require verifying the graph, not \u201csomeone said it passed.\u201d","connections":[58,92]},{"id":45,"name":"content-addressed-storage","title":"Content-addressed storage: immutability by digest makes rollbacks pointer moves","formal":"store content at address (h(content)). Integrity and identity unify.","apm2_mapping":"CAS is already core: evidence artifacts, prompts, scopes, and packs are hash-addressed. The key operational leap: treat all important state as *references* to CAS content; mutable pointers live in small, auditable consensual state.","connections":[46,47,49]},{"id":46,"name":"merkle-trees-hash-chaining","title":"Merkle trees + hash chaining: tamper evidence at scale","formal":"hash chain gives linear integrity; Merkle trees give efficient inclusion proofs.","apm2_mapping":"ledger hash chaining exists; consensus module includes Merkle structures. Use Merkle roots for efficient replication proofs and for \u201caudit sampling\u201d without full log transfer.","connections":[49,66]},{"id":47,"name":"event-sourcing","title":"Event sourcing: model system as sequence of decisions, not hidden state mutation","formal":"state is a fold over events:\n[\nstate_t = fold(apply, state_0, events_{0:t})\n]","apm2_mapping":"this is literally APM2\u2019s kernel: ledger events + deterministic reducers. Operationally: \u201cthe truth\u201d is the event stream + CAS. Everything else is a projection.","connections":[59,95]},{"id":48,"name":"idempotency-keys-deduplication","title":"Idempotency keys + deduplication: retries must be safe","formal":"operation (op(k)) with idempotency key (k) must satisfy (op(k)) applied multiple times \u2261 once.","apm2_mapping":"tool requests already include `dedupe_key`, and work transitions include sequence checks. Make idempotency a hard requirement for any side-effecting tool: file writes, git ops, deploys. If you cannot make it idempotent, wrap it in a transactional boundary and record a receipt.","connections":[53,54,92]},{"id":49,"name":"consensus-keeps-one-truth-for-critical-control-state-minimize-what-needs-consensus","title":"Consensus keeps one truth for critical control state; minimize what needs consensus","formal":"consensus replicates a state machine; cost is high, so keep the replicated state small.","apm2_mapping":"store bulk data in CAS; store events in ledger; replicate only the minimal \u201cpointers\u201d and membership state. The BFT backend exists; your future pain will be \u201cwhat did we mistakenly put into consensus?\u201d Keep it austere.","connections":[45,47]},{"id":50,"name":"vector-clocks-causal-consistency","title":"Vector clocks + causal consistency: encode partial order, don\u2019t pretend in wall time","formal":"vector clocks represent causality; (a \\rightarrow b) if all components \u2264 and at least one <.","apm2_mapping":"APM2 already uses HLC fields, which are a practical compromise between Lamport and wall-clock. Extend causal encoding into work DAGs: parent_work_ids and gate dependencies are explicit causality. Avoid deriving causality from timestamps.","connections":[30,95]},{"id":51,"name":"crdts","title":"CRDTs: some state can converge without coordination","formal":"CRDTs rely on a join-semilattice ((S,\\sqcup)) and monotone updates; eventual convergence is guaranteed.","apm2_mapping":"consensus module includes CRDTs. Use CRDTs for *non-critical* shared views: caches, indexes, presence, \u201cbest effort\u201d telemetry summaries. Never use CRDTs for authority or money unless you deeply understand the algebra and threat model.","connections":[71,87]},{"id":52,"name":"actor-model","title":"Actor model: isolate failures by message-driven components with supervision","formal":"actors have mailboxes; no shared mutable state; supervisors restart.","apm2_mapping":"holons are actors: they intake work, execute bounded episodes, emit artifacts, and can be supervised/escalated. Keep the actor boundary crisp: message schemas + capability tokens are the only ingress.","connections":[53,55]},{"id":53,"name":"backpressure","title":"Backpressure: the only honest overload strategy","formal":"when downstream cannot process, upstream must slow/stop; otherwise queues explode.","apm2_mapping":"APM2 already implements backpressure in resource governance for pulse subscriptions and in budgets for sessions. Push it everywhere: tool execution pools, replication streams, CI import, gate evaluation. Also: treat \u201ccannot accept work\u201d as a normal outcome, not an error.","connections":[9,25,27]},{"id":54,"name":"circuit-breakers","title":"Circuit breakers: prevent cascading failures","formal":"open circuit after repeated failures; half-open to test recovery.","apm2_mapping":"apply to external dependencies (LLM providers, GitHub API, artifact stores). The breaker state should be visible in the ledger or in a projection so it can be audited and tuned, not hidden in logs.","connections":[63,64]},{"id":55,"name":"bulkheads-compartmentalization","title":"Bulkheads/compartmentalization: bound blast radius across partitions","formal":"isolate resources so failure doesn\u2019t spread.","apm2_mapping":"enforce partitions at **network**, **identity**, and **capability** layers. Work DAG partitioning (24) gives you a natural bulkhead boundary; enforce it mechanically, not socially.","connections":[38,39,62]},{"id":56,"name":"graceful-degradation","title":"Graceful degradation: preserve core functions under failure","formal":"drop optional features first; preserve invariants.","apm2_mapping":"under control-plane distress, the system must remain **readable**: ledger and evidence retrieval should keep working even if scheduling and tool orchestration degrade. That\u2019s \u201ccontent plane readable when control plane unhealthy.\u201d","connections":[25,66]},{"id":57,"name":"fair-scheduling-weighted-queuing","title":"Fair scheduling + weighted queuing: prevent starvation","formal":"allocate service according to weights; avoid head-of-line blocking.","apm2_mapping":"APM2 should weight by **risk tier**, **SLO**, and **tenant**. \u201cOne noisy agent\u201d must not starve governance-critical loops (leases, capability revocation, ledger append). Encode fairness in schedulers and in HEF drop policy priorities.","connections":[25,94]},{"id":58,"name":"deterministic-builds-hermetic-environments","title":"Deterministic builds + hermetic environments: reproducibility is security","formal":"build output must be a pure function of inputs; hermeticity removes hidden dependencies.","apm2_mapping":"this is foundational for evidence credibility. Without determinism, you cannot reproduce a receipt. Treat hermeticity as a gate requirement for high-stakes promotions.","connections":[31,44,92]},{"id":59,"name":"declarative-reconciliation-loops","title":"Declarative reconciliation loops: desired vs observed state","formal":"controllers compute (diff(desired, observed)) and apply corrections until convergence.","apm2_mapping":"reducers are \u201cobserved state,\u201d PRDs/RFCs/tickets are \u201cdesired state,\u201d and gates are reconciliation checks. Extend reconciliation to infrastructure: policy bundles, schema registries, key distribution.","connections":[47,60]},{"id":60,"name":"configuration-drift-is-inevitable-detect-and-remediate-continuously","title":"Configuration drift is inevitable; detect and remediate continuously","formal":"drift = observed \u2260 desired; remediation must be audited.","apm2_mapping":"in global deployments, drift is both reliability and security risk. Drift remediation must emit evidence (what changed, why, by whom, which capability).","connections":[92,93]},{"id":61,"name":"bare-metal-provisioning","title":"Bare metal provisioning: you need a substrate API (BMC/Redfish/PXE/golden images)","formal":"if you own hardware, provisioning is control theory + security.","apm2_mapping":"Phase\u20114/5 require fleet control. Define a rack substrate API early, or you\u2019ll re-invent cloud primitives badly.","connections":[36,37]},{"id":62,"name":"failure-domains-define-correlated-risk-schedule-with-failure-domain-awareness","title":"Failure domains define correlated risk; schedule with failure-domain awareness","formal":"correlated failures violate independence assumptions; replication must straddle domains.","apm2_mapping":"for consensus and evidence replication, spread across domains (rack, ToR switch, power feed). For work scheduling, avoid placing all parents/children in same failure domain.","connections":[24,49]},{"id":63,"name":"slos-error-budgets","title":"SLOs + error budgets: reliability becomes an optimization constraint","formal":"error budget = allowed failures within window; treat reliability as spendable.","apm2_mapping":"APM2\u2019s autonomy levels should \u201cspend\u201d reliability budget. High-risk autonomous actions must require more budget headroom (i.e., be conservative when budget is low). Encode this into gates and policies.","connections":[64,94]},{"id":64,"name":"burn-rate-alerting","title":"Burn-rate alerting: page on budget consumption, not raw errors","formal":"burn rate = current error rate / allowed error rate; page if sustained > threshold.","apm2_mapping":"incident holons should trigger on \u201cbudget being consumed too fast.\u201d This applies to: CI flakes, tool errors, policy denials, replication failures. It\u2019s the correct control signal.","connections":[29,67]},{"id":65,"name":"tracing-with-correlation-ids","title":"Tracing with correlation IDs: make causality observable","formal":"propagate trace context end-to-end; reconstruct causality graph.","apm2_mapping":"every work item, tool request, gate receipt, and deploy should carry a trace ID. This is required for record/replay (31) and for causal debugging under concurrency.","connections":[30,50]},{"id":66,"name":"sampling-aggregation","title":"Sampling + aggregation: mandatory at scale; policies must be risk-aware","formal":"logging everything is an economic DoS; sampling must preserve critical signals.","apm2_mapping":"classify telemetry by risk tier and data classification. High-risk events get durable evidence; low-risk gets sampled stats. Encode sampling policy as signed bundles (93) so enforcement is uniform.","connections":[42,87]},{"id":67,"name":"chaos-engineering","title":"Chaos engineering: validate assumptions under controlled failure","formal":"inject faults to test resilience, not just correctness.","apm2_mapping":"use fault injection as continuous safety tests: partitions, message drops, clock skew, corrupted artifacts, revoked capabilities. APM2\u2019s event sourcing makes postmortems crisp because you can replay history.","connections":[31,99]},{"id":68,"name":"tla-model-checking","title":"TLA+/model checking: catch distributed bugs early","formal":"specify state machines; model-check safety/liveness; find counterexamples.","apm2_mapping":"core protocols (lease issuance, capability delegation, ledger append/replication, gate promotion) are *absolutely* worth formal modeling. The cost of a distributed safety bug is existential.","connections":[49,50,51,82]},{"id":69,"name":"type-effect-systems","title":"Type/effect systems: encode allowed actions in types","formal":"effects annotate functions: (f : A \\to B ; !{net, fs, deploy}).","apm2_mapping":"protobuf tool schemas + validation is a runtime approximation of effect systems. Push further: tool APIs should surface effects explicitly and require capabilities per effect class.","connections":[90,91]},{"id":70,"name":"refinement-types-contracts","title":"Refinement types/contracts: checked invariants at boundaries","formal":"types with predicates: ({x:\\text{String} \\mid len(x)\\le256}).","apm2_mapping":"APM2 already enforces strict bounds (IDs, sizes, paths). This is what stops DoS and injection. Keep pushing: schemas should deny unknown fields; contracts should be explicit and validated at every boundary.","connections":[89,90]},{"id":71,"name":"lattice-theory-monotone-frameworks","title":"Lattice theory + monotone frameworks: explain convergence and termination","formal":"if (f) is monotone on a complete lattice, iterating from (\\bot) converges to (\\mathrm{lfp}(f)).","apm2_mapping":"permissions and delegation are lattices; CRDTs are semilattices; policy evaluation should be monotone and terminating. This is not abstract math\u2014it\u2019s how you guarantee no permission propagation loops and no non-terminating reconciliation.","connections":[38,51,72]},{"id":72,"name":"fixed-point-semantics","title":"Fixed-point semantics: recursive definitions as least fixed points","formal":"holonic nesting and recursion must be specified as fixed points to avoid ambiguity.","apm2_mapping":"\u201cholon supervising holon\u201d is recursion. Define nesting semantics so that delegation, budgets, and stop conditions compose and terminate. Otherwise you get spawn storms.","connections":[53,80]},{"id":73,"name":"category-theory","title":"Category theory: compositional interfaces with identity + associativity","formal":"morphisms compose; identities exist; compositionality reduces complexity.","apm2_mapping":"holon interfaces should compose: work intake \u2192 episode execution \u2192 artifact emission \u2192 escalation. Tool invocations should also be composable pipelines with explicit handlers (74). The point is to build large systems from small verified pieces without \u201cglue code entropy.\u201d","connections":[74,95]},{"id":74,"name":"monads-algebraic-effects","title":"Monads/algebraic effects: disciplined sequencing of side effects","formal":"effects are explicit; handlers interpret them; sequencing becomes structured.","apm2_mapping":"treat tool usage as effectful computation: requests are effect values; the kernel is the handler enforcing policy and budgets. This is how you prevent \u201cagent prose\u201d from being an implicit effect system.","connections":[69,70,89,90]},{"id":75,"name":"convex-optimization","title":"Convex optimization: global guarantees under constraints","formal":"many allocation problems can be posed as convex programs with reliable solvers.","apm2_mapping":"scheduling, budgeting, placement, and admission are optimization problems under constraints (SLOs, risk tiers, failure domains). Start with convex relaxations; only go heuristic when necessary. The key is that convex programs produce *auditable* decisions and sensitivities.","connections":[27,28,83]},{"id":76,"name":"bayesian-inference","title":"Bayesian inference: belief updating, not confidence prose","formal":"[\nP(H\\mid D)\\propto P(D\\mid H)P(H)\n]","apm2_mapping":"\u201cagent confidence\u201d must become explicit uncertainty state: beliefs over whether a change is correct, whether a tool output is trustworthy, whether a regression is real. Use evidence as likelihood updates. This aligns with gates: a gate receipt is a high-weight observation.","connections":[79,92]},{"id":77,"name":"stochastic-processes","title":"Stochastic processes: distinguish drift/regime changes from noise","formal":"treat metrics as stochastic processes; detect change points vs transient outliers.","apm2_mapping":"avoid thrashing policies due to transient CI flakes or provider outages. Maintain change detection with robust statistics (87) and explicit \u201cregime state\u201d in projections.","connections":[29,87]},{"id":78,"name":"mdps","title":"MDPs: sequential decision-making optimizing long-run cost","formal":"state (s), actions (a), transitions (P(s'|s,a)), reward (R).","apm2_mapping":"the factory loop is an MDP: choose next action (tool call, gate, escalation) to optimize long-run \u201cverified progress per cost\u201d under constraints. But don\u2019t let RL \u201coptimize\u201d without governance: it will Goodhart metrics.","connections":[84,85,86,94]},{"id":79,"name":"pomdps","title":"POMDPs: partial observability requires belief states","formal":"maintain belief (b(s)) over hidden state; update with observations.","apm2_mapping":"agents do not observe the world fully; tool outputs are partial and sometimes adversarial. Maintain belief states tied to evidence, not narratives. This is exactly why APM2 treats tool outputs as untrusted until verified/hashed/stored.","connections":[76,88,89,90]},{"id":80,"name":"hierarchical-rl","title":"Hierarchical RL: delegation as options with initiation/termination","formal":"options (o) have policies (\\pi_o), initiation sets (I_o), termination (\\beta_o).","apm2_mapping":"holons supervising sub-holons are options. Encode initiation/termination conditions as contracts and stop conditions in the holon trait context. Delegation without termination conditions is how you get infinite recursion and runaway autonomy.","connections":[72,94]},{"id":81,"name":"skill-discovery-option-libraries","title":"Skill discovery + option libraries: store verified playbooks as callable skills","formal":"convert experience into reusable policies with known preconditions and effects.","apm2_mapping":"this is literally the \u201cskills\u201d directory philosophy: executable specifications. But the key word is **verified**: store not just the steps but the evidence patterns and the gates that validate them.","connections":[92,98]},{"id":82,"name":"sat-smt","title":"SAT/SMT: encode hard invariants as satisfiable constraints","formal":"constraints are boolean/first-order; solver finds model or proves UNSAT.","apm2_mapping":"deployment and security policy should be constraints, not ad-hoc checks: \u201cno tool call with net=true unless capability X,\u201d \u201cno merge unless evidence bundle contains Y,\u201d \u201cno downgrade of classification.\u201d Where possible, compile policy into SAT/SMT for decidability and audit.","connections":[68,93]},{"id":83,"name":"distributed-constraint-optimization-auctions","title":"Distributed constraint optimization + auctions: scalable allocation mechanisms","formal":"agents bid; allocation solves approximate global objective under limited coordination.","apm2_mapping":"use market-like allocation for compute slots, inference tokens, and CI capacity across holons, but only for *non-authority* resources. Authority allocation is governance, not an auction.","connections":[84,85]},{"id":84,"name":"game-theory","title":"Game theory: assume strategic or misaligned sub-agents","formal":"model agents as utility maximizers; equilibria can be bad if incentives mis-specified.","apm2_mapping":"treat internal agents as potentially adversarial (this is in the threat model). Therefore: (a) verify claims mechanically (92), (b) bound authority (38), (c) use audits and witnesses, (d) don\u2019t reward narrative.","connections":[85,89]},{"id":85,"name":"mechanism-design","title":"Mechanism design: make truthful reporting stable","formal":"design incentives so truthful reporting is a dominant strategy or equilibrium.","apm2_mapping":"\u201creward\u201d should mean \u201cadvance work state\u201d only when evidence checks pass. If an agent can progress by persuasion, you\u2019ve built a lying machine. Gates and receipts are the incentive mechanism.","connections":[92,94]},{"id":86,"name":"causal-inference","title":"Causal inference: don\u2019t remediate based on spurious correlation","formal":"distinguish (P(Y|X)) from (P(Y|do(X))); interventions matter.","apm2_mapping":"auto-remediation must be intervention-driven: test a change, observe the counterfactual, roll back if not causal. Canarying and controlled experiments are the causal tool.","connections":[67,99]},{"id":87,"name":"robust-statistics","title":"Robust statistics: resist outliers and adversarial noise","formal":"prefer estimators with high breakdown point (median, trimmed mean, Huber loss).","apm2_mapping":"metrics and telemetry are attack surfaces. Use robust estimators for burn-rate decisions and anomaly detection; otherwise a single malicious/buggy holon can steer the controller.","connections":[77,84]},{"id":88,"name":"adversarial-ml","title":"Adversarial ML: treat inputs as attack surfaces","formal":"optimize worst-case loss under bounded perturbations; in practice, treat all model inputs as untrusted.","apm2_mapping":"prompts, retrieved context, tool outputs are *untrusted*. The safe design is: strict schemas, capability separation, hermetic sandboxes, and denial-by-default tools.","connections":[89,90,91]},{"id":89,"name":"prompt-injection-is-confused-deputy-robust-mitigation-is-capability-separation-deny-by-default","title":"Prompt injection is confused deputy; robust mitigation is capability separation + deny-by-default","formal":"confused deputy: an untrusted party tricks a privileged actor into misusing authority.","apm2_mapping":"the tool protocol is the deputy boundary. The only real fix is that the agent never has ambient authority: it must present explicit capabilities, and tools must validate strict schemas and scopes. Everything else is theater.","connections":[38,90,91]},{"id":90,"name":"typed-tool-schemas-structured-outputs","title":"Typed tool schemas + structured outputs: validate and parse, don\u2019t \u201cinterpret\u201d prose","formal":"schemas define admissible messages; parsing failures are denials.","apm2_mapping":"protobuf + validation is exactly right. The next step is ensuring every tool response is also structured and content-addressed, so downstream reasoning is about hashes and receipts, not uncontrolled text.","connections":[31,92]},{"id":91,"name":"sandboxing-with-deny-by-default-network-filesystem-scopes-bounds-damage","title":"Sandboxing with deny-by-default network/filesystem scopes bounds damage","formal":"confinement is a safety invariant; capability grants are exceptions.","apm2_mapping":"make sandboxing non-optional for executors. Policy is not enough; enforce at OS boundary (32). Capability grants should be narrow, time-bounded, and logged.","connections":[34,35,43]},{"id":92,"name":"evidence-carrying-actions","title":"Evidence-carrying actions: every merge/deploy requires machine-checkable receipts","formal":"action validity predicate:\n[\nValid(Output,Receipt,Evidence)=VerifyReceipt \\wedge EvidenceSatisfies(contract) \\wedge DigestBindingsHold\n]\n(Exactly the direction APM2\u2019s unified theory pushes.)","apm2_mapping":"AAT bundles, merge receipts, CI attestations\u2014these are not \u201cdocs,\u201d they are the core security boundary. Anything not bound to evidence is not real.","connections":[44,45,46,47,85]},{"id":93,"name":"policy-as-code-with-signed-bundles","title":"Policy-as-code with signed bundles: distributable governance with consistent enforcement","formal":"policy hash (h(P)) is the governance identity; enforcement requires exact match.","apm2_mapping":"every holon must enforce the same policy hash for a given risk tier before acting. Signed policy bundles prevent drift and downgrade.","connections":[41,60]},{"id":94,"name":"risk-classes-autonomy-levels","title":"Risk classes + autonomy levels: gate authority by evidence and risk","formal":"define an authority lattice and a promotion function:\n[\nauthority = f(risk, evidence, budget_headroom)\n]","apm2_mapping":"APM2 already encodes risk tiers in factory logic; make it universal: suggest \u2192 patch \u2192 merge \u2192 deploy are different \u201ceffect classes\u201d requiring escalating receipts and isolation.","connections":[63,89,90,91,92]},{"id":95,"name":"work-graphs-as-dags","title":"Work graphs as DAGs: ordering must be explicit and replayable","formal":"represent work as state machines + DAG edges; replay derives state.","apm2_mapping":"the work module already includes parent_work_ids and immutable spec_snapshot_hash. The right posture is: **work is a replayable automaton**, not a chat log. \u201cConversation\u201d is a projection; the ledger is truth.","connections":[47,50]},{"id":96,"name":"cognitive-memory-hierarchy-maps-to-caches-and-stores","title":"Cognitive memory hierarchy maps to caches and stores: tier memory explicitly","formal":"working memory (fast/volatile), episodic memory (append-only), semantic memory (index).","apm2_mapping":"working context is lossy and budgeted; episodic memory is ledger; semantic memory is future index, but must be versioned and invalidated like caches.","connections":[21,97]},{"id":97,"name":"rag-is-cache-coherence","title":"RAG is cache coherence: versioning, invalidation, budgets","formal":"coherence requires: versions, invalidation rules, bounded staleness.","apm2_mapping":"retrieval must be content-addressed, version-pinned, and budgeted. ContextPack compilation is coherence: it pins roots and resolves transitive dependencies deterministically. Treat \u201cstale context\u201d as a coherence bug, not \u201cmodel weirdness.\u201d","connections":[4,5,14,15]},{"id":98,"name":"differential-testing-continuous-red-teaming","title":"Differential testing + continuous red-teaming: find regressions and exploit paths","formal":"compare behaviors across implementations/versions; adversarial suites probe weak spots.","apm2_mapping":"red-team the tool protocol, policy engine, and gate semantics continuously. Differentially test canonicalization, hashing, schema validation, and replay determinism. These are the parts attackers target because they define truth.","connections":[67,88,89,90]},{"id":99,"name":"sociotechnical-incident-response","title":"Sociotechnical incident response: convert failure into stronger contracts and rollback triggers","formal":"postmortems produce actionable countermeasures; automate rollback based on SLO/budget triggers.","apm2_mapping":"incidents should mint new defects and new gates. If a failure mode happens twice, governance failed. Tie rollback triggers to burn-rate and to explicit receipts, not human panic. This is how Phase\u20111 recursion becomes monotonic improvement.","connections":[63,64,67,92]}]}}