# RFC-0007 Amendment A2: FAC Execution Substrate / Local Build Farm Kernel (Execution Lanes, Queue, Hygiene, Attestation)

* **Document:** `documents/rfcs/RFC-0007/10_fac_execution_substrate_build_farm_revision.md`
* **Amends:** RFC-0007 (DRAFT)
* **Date:** 2026-02-12
* **Primary surfaces touched by this amendment:**

  * `crates/apm2-cli/src/commands/fac.rs`
  * `crates/apm2-cli/src/commands/fac_review/{gates,evidence,gate_attestation}.rs`
  * `scripts/ci/run_bounded_tests.sh`
  * `flake.nix`
  * `documents/skills/implementor-default/SKILL.md`
  * (NEW) `crates/apm2-cli/src/commands/fac_review/{lane,queue,executor,fac_resources,target_pool}.rs` (exact module layout is flexible; semantics are not)
  * (NEW) `crates/apm2-core/src/fac/{receipt_stream,hlc}.rs` (design seam; implementation may start in apm2-cli and migrate)
* **Motivating operational constraints (explicit):**

  * Ubuntu 24.04
  * 96 GB RAM
  * Frequently **≤ 3 simultaneous** `gate` executions across **3 worktrees**
  * Often **~13 worktrees exist concurrently** (not all active)
  * Near-term: heavy bash → Rust migration (security + perf)
  * Long-term: assimilate to **NixOS substrate** across the holonic network
  * Primary goal: **maximize FAC loop throughput** while guaranteeing **no catastrophic host failure** (disk/mem/CPU exhaustion), with **automatic/enforced cleanup**
  * Networking is **not available yet**; all semantics MUST be local-first with clean seams for later distribution.

---

## 0. Non-negotiable requirements (normative)

This amendment is a build-farm "kernel" spec. The following are MUSTs:

1. **Safety > speed.** The substrate MUST prevent catastrophic host failure (disk/mem/CPU/PIDs/IO exhaustion) even with multiple autonomous agents.
2. **Incremental deployability.** Every phase MUST be useful on a single VPS, MUST have rollback, and MUST NOT require a distributed system.
3. **Networkless semantics.** Job/lane semantics MUST NOT assume networking. Networking is a bolt-on transport layer later.
4. **Declarative substrate target.** The design MUST map cleanly to flakes now and future NixOS modules later.
5. **Fail-closed attestation semantics.** If anything that can affect correctness changes, gate-cache reuse MUST NOT silently continue.
6. **No ambient user state reliance.** FAC MUST NOT depend on aliases/dotfiles/`~/.cargo/config.toml`; FAC MUST set policy explicitly.
7. **No new long-lived bash daemons.** Control plane MUST be Rust and/or systemd-managed units. Bash scripts may exist only as transitional leaf executors.

## 0.1 Terminology (local build-farm primitives)

* **Lane**: A bounded, cullable execution context with deterministic identity, dedicated workspace+target namespace, and a fixed resource profile.
* **Job**: An immutable spec (what to run, against which inputs) that is queued, leased to a lane, executed, and yields receipts.
* **Receipt stream**: An append-only, mergeable (CRDT-compatible) set/log of receipts; receipts are the ground truth, not runtime state.
* **Execution profile**: The attested environment+policy facts (including lane profile hash + toolchain fingerprint) that gate-cache keys depend on.

## 1. Repo-grounded baseline: what actually runs today

This amendment is written against the **current apm2 repo state** in the provided ZIP.

### 1.1 FAC gates execution path (local)

`apm2 fac gates` is implemented in:

* `crates/apm2-cli/src/commands/fac.rs` → routes to
* `crates/apm2-cli/src/commands/fac_review/gates.rs::run_gates(...)`

`run_gates` calls:

* `fac_review/evidence.rs::run_evidence_gates(...)`

Evidence gates include:

* `cargo fmt --all --check`
* `cargo clippy --workspace --all-targets --all-features -- -D warnings`
* `cargo doc --workspace --no-deps`
* `scripts/ci/test_safety_guard.sh`
* `scripts/ci/workspace_integrity_guard.sh`
* `scripts/ci/review_artifact_lint.sh`
* **test gate**: uses `cargo nextest run ...` inside `scripts/ci/run_bounded_tests.sh` when cgroup v2 is available.

Key fact: **nextest is already the default execution for the test gate** when the bounded runner path is active (the pipeline builder constructs `cargo nextest run ...`). **However, both the pipeline and local gates paths still fall back to `cargo test`** when bounded execution is unavailable or when `EvidenceGateOptions.test_command` is unset.

Clarification (missing in the draft): **there are two "fallback" paths today**:

* **Pipeline path** (`run_evidence_gates_with_status`) uses `build_pipeline_test_command(...)` and falls back to `cargo test` if bounded runner isn't available.
* **Local `apm2 fac gates` path** (`run_evidence_gates(...)` via `gates.rs`) runs whatever `gates.rs` passes as `EvidenceGateOptions.test_command`. If `gates.rs` does **not** pass a command (e.g., bounded runner unavailable), `run_evidence_gates` falls back to `cargo test` directly.

If we "mandate nextest", we must fix **both** call paths (pipeline + local), not just the pipeline builder.

### 1.2 Bounded test environment today

The bounded runner:

* Uses `systemd-run --user` transient scope/service under a name like `apm2-ci-bounded-...`
* Enforces:

  * timeout (defaults bounded by `gates.rs` max 240s)
  * memory max (default 24G passed from CLI)
  * pids max
  * CPU quota
* Uses an **explicit allowlist** to propagate selected env vars into the unit (`run_bounded_tests.sh` has `SETENV_ARGS` built from a for-loop allowlist).

Operational footgun (needs to be treated as a *substrate requirement*, not a "maybe"):

* `systemd-run --user` requires a functioning user bus. On headless/VPS setups this frequently fails unless the user session is correctly configured (and CI uses a documented workaround). This amendment therefore treats "bounded runner availability" as a **first-class availability constraint**, not a "maybe".

Correctness footgun (missing in the draft, and currently **fail-open**):

* Gate cache keys are derived from `git rev-parse HEAD` (a commit SHA). **If the working tree has uncommitted changes, the SHA does not change**, so cache reuse can become incorrect. This substrate MUST either:
  * require a clean worktree to use gate cache (fail-closed), OR
  * incorporate a "dirty diff digest" (or patch artifact hash) into the attested inputs.

### 1.3 Gate cache and attestation today

Gate cache receipts are written (in full mode) under:

* `~/.apm2/private/fac/gate_cache_v2/<SHA>/...`

Attestation digest computation is in:

* `crates/apm2-cli/src/commands/fac_review/gate_attestation.rs`

Important details:

* `command_digest()` hashes an allowlisted set of environment variables (e.g., `RUSTFLAGS`, `RUSTDOCFLAGS`, `CARGO_BUILD_JOBS`, `CARGO_INCREMENTAL`, `RUSTUP_TOOLCHAIN`).
* `gate_input_digest()` hashes selected paths (e.g., `.config/nextest.toml`, `scripts/ci/run_bounded_tests.sh`), but **does not currently include `.cargo/config.toml`**.
* `environment_digest()` includes versions for: kernel, rustc, cargo, rustfmt, clippy, nextest, systemd-run. **No sccache version** is captured today.

Correction (repo-grounded): `environment_digest()` currently captures **string outputs** from:

* kernel (`uname -sr`)
* rustc (`rustc --version`)
* cargo (`cargo --version`)
* clippy (`cargo clippy --version`)
* nextest (`cargo nextest --version`)
* systemd-run (`systemd-run --version`)

It does **not** capture `rustfmt --version` today (latent fail-open for fmt-gate correctness across toolchain changes).

This matters: any "build cache substrate" change must be surfaced into attestation in a way that remains **fail-closed** (no unsafe reuse).

Repo-grounded missing pieces that matter to fail-closed semantics:

* `.cargo/config.toml` already exists in-repo and materially changes builds (e.g., linker + rustflags). It is currently **not** included in attestation input digests.
* `~/.cargo/config.toml` (ambient) can also change builds. The substrate MUST NOT depend on it; the safe approach is to set `CARGO_HOME` under `$APM2_HOME` for FAC executions and treat the FAC-managed cargo config as authoritative policy input.

---

## 2. Problem statement (what must become true)

### 2.1 The real bottleneck is not "tests are slow"; it's uncontrolled shared-host resource collapse

Observed operational pattern:

* Many git worktrees exist simultaneously (often ~13).
* Each worktree has its own `target/` directory by default.
* Compilation-heavy gates (`clippy`, `doc`, `test`) can each trigger distinct compilation flows and output sets.
* The **bounded** test gate is sensitive: if it has to do a large cold compile, it can exceed:

  * **Wall-time 240s** (by policy; should not be increased)
  * **MemoryMax 24G** (policy default)

Your stated goal is not to "relax the box"; it is to **make cold-start rare** and **keep the host stable** under parallel agents.

### 2.2 Failure modes to treat as first-class (explicitly in substrate semantics)

1. **Disk exhaustion** (targets/logs/evidence artifacts) is the dominant catastrophic failure mode.
2. **CPU/IO thrash** from unbounded parallel cargo/clippy/doc/test invocations is the second.
3. **PID exhaustion** and **runaway processes** are the third (especially with nextest default concurrency).
4. **Containment bypass** is a security and correctness risk if any helper (e.g., sccache) can execute compilers outside the bounded unit.
5. **Incorrect cache reuse** (dirty tree, missing inputs, missing tool versions) is correctness failure, not just "cache isn't perfect".
6. **Symlink/rmtree disasters** during cleanup/reset are catastrophic and must be engineered out.

The current "compute slots + target pool" proposal is necessary but insufficient: it addresses concurrency and caching, but it does not define the **unit of containment** (lane), **job semantics**, **queueing**, **leases**, or **receipts as ground truth**.

---

## 3. What this amendment changes in RFC-0007 (and why it still belongs in RFC-0007)

RFC-0007 (currently DRAFT) is about build optimizations; it already contains:

* `TB-002: Compilation Cache` (sccache) in `03_trust_boundaries.yaml`
* Optional nextest decisions (`DD-002`, `DD-003`) in `02_design_decisions.yaml`

This amendment modifies RFC-0007 in four ways (execution substrate is a build optimization when done correctly):

1. It upgrades "optional nextest" to a **mandatory FAC test runner policy** (explicit invocation; no alias reliance).
2. It replaces "worktree is the execution unit" with a **finite execution lane pool** (lane = blast radius).
3. It turns "cross-worktree build reuse" into a **lane-scoped target namespace** (target pool per lane, per toolchain fingerprint).
4. It makes **resource hygiene and enforced preflight** part of the FAC substrate contract, not a human ritual.

Ordering of accelerators remains:

   **Primary accelerator (new):** slot-scoped `CARGO_TARGET_DIR` pool ("target pool").

   **Secondary accelerator (optional, gated):** sccache, only after containment + benefit verification.

This amendment explicitly **does not** attempt to redesign FAC protocol cryptography; it is about the **local execution substrate** and safety of running many agents.

---

## 4. FAC Execution Substrate v1 (FESv1): execution lanes + local scheduler (networkless)

FESv1 is the "local build farm kernel" for APM2 agents.

### 4.1 Entities (stable semantics; distribution later)

* **Node**: a single host instance (today: one Ubuntu VPS). Future: many nodes under headscale.
* **Lane**: a bounded execution context on a node with deterministic identity and a fixed resource profile.
* **Job**: an immutable spec that produces receipts and evidence artifacts.
* **Scheduler**: local-only dispatcher that leases jobs to lanes with backpressure.
* **Receipt**: an append-only record; the ground truth (ledger-first).

### 4.2 Execution lanes (required model)

Each lane is:

* a git worktree rooted at: `$APM2_HOME/private/fac/lanes/<lane_id>/workspace`
* a long-lived, **cullable** execution context (resettable without touching other lanes)
* a fixed resource profile (enforced via systemd/cgroups)
* a dedicated target namespace: `$APM2_HOME/private/fac/lanes/<lane_id>/target/<toolchain_fingerprint>`
* a dedicated log namespace: `$APM2_HOME/private/fac/lanes/<lane_id>/logs`

Lane lifecycle (persisted via receipts + lease records; runtime is not authoritative):

`IDLE → LEASED → RUNNING → CLEANUP → IDLE`

Exceptional:

`* → CORRUPT → RESET → IDLE`

### 4.3 Backpressure is lane-count + lane profiles (not "worktrees")

The substrate MUST enforce a finite number of concurrent heavy jobs by construction:

* `lane_count` is finite (default derived from memory policy; on the current box: 3).
* each lane runs **at most one job at a time** (exclusive lease).
* each job executes under lane resource limits (CPU/memory/PIDs/IO + timeouts).

### 4.4 Leasing (mechanism, not vibes)

Leasing is a file-lock + durable lease record:

* Lock file: `$APM2_HOME/private/fac/locks/lanes/<lane_id>.lock`
* Lease record: `$APM2_HOME/private/fac/lanes/<lane_id>/lease.v1.json`

Rules:

* lease acquisition MUST be atomic and exclusive (reuse the existing file-lock leasing pattern used by `fac_review/model_pool.rs`).
* lease record MUST include: `job_id`, `pid`, `started_at`, `lane_profile_hash`, `toolchain_fingerprint`.
* stale lease handling MUST be fail-closed:
  * if lock is free but lease record claims RUNNING and the pid is alive → treat as CORRUPT and require reset
  * if lock is free and pid is dead → scheduler may transition to CLEANUP and then IDLE (writing receipts)

### 4.5 Job queue (local-first; distribution later)

Queue is a filesystem-backed ordered set of job specs under `$APM2_HOME/private/fac/queue`.

Required properties:

* FIFO within a priority band
* explicit priority levels (small integer; higher wins)
* cancellation by job id
* atomic claiming (no double-execution)
* crash tolerance (claimed jobs must requeue or be marked failed with receipt)

Minimal viable layout:

* `queue/pending/`
* `queue/claimed/`
* `queue/done/`
* `queue/cancelled/`

Claim algorithm (local-only):

1. Workers (either CLI or daemonized `apm2-daemon` later) scan `pending/` for highest priority then oldest `enqueued_at`.
2. Claim uses atomic `rename()` from `pending/<job_id>.json` → `claimed/<job_id>.json`.
3. The claiming worker then acquires a lane lease and executes the job.

This is the networkless seam: a future distributed scheduler can transport `FacJobSpecV1` objects and still use the same lane/job semantics.

### 4.6 Containment: all compilers/tests MUST run inside bounded units

Baseline requirement: cargo, rustc, nextest, and any helper processes spawned by the job MUST remain inside the intended cgroup boundary for the lane/job.

Mechanism (Phase 1, user-mode):

* execute each job via `systemd-run --user` transient units with explicit properties derived from `LaneProfileV1`.

Mechanism (Phase 3, stronger brokered mode; optional but recommended for hostile workloads):

* a systemd **system** unit executes jobs as a dedicated service user (no user-bus), preventing "spawn new user units" escape hatches.

If bounded execution cannot be proven available, FAC MUST fail closed with actionable remediation (enable linger / run via systemd-managed apm2-daemon).

### 4.7 Cleanup/reset MUST be symlink-safe (rmtree disasters are catastrophic)

GC and lane reset MUST NOT use naive recursive deletion (e.g., `rm -rf` or `std::fs::remove_dir_all`) on paths influenced by lane/job state.

Required deletion primitive: `safe_rmtree_v1(root, allowed_parent)`:

* canonicalize `allowed_parent` and `root`
* verify `root.starts_with(allowed_parent)` after canonicalization
* refuse to operate if **any path component** between `allowed_parent` and `root` is a symlink
* delete by walking directory entries using `symlink_metadata()` and:
  * unlink symlinks as files (do not follow)
  * recurse into directories only after verifying they are not symlinks
* on any ambiguity or TOCTOU suspicion → fail closed and mark lane CORRUPT (requires manual reset)

This is non-negotiable: one symlink bug can delete the host.

### 4.8 Cross-job contamination controls (lane reset protocol)

Each job MUST end in a cleanup step before the lane returns to IDLE:

* hard reset the git worktree to the job's attested revision
* `git clean -ffdx` (or equivalent) inside the lane workspace
* remove lane-local temp dirs (`target/tmp`, nextest temp, etc.)
* enforce log retention/quota per lane (size and TTL)

If cleanup fails, the lane MUST be marked CORRUPT and refused for further leases until reset.

---

## 5. Interfaces (precise; implementable)

This section is normative. If an interface is not specified here, it is not part of the substrate contract.

### 5.1 Directory layout under `$APM2_HOME` (authoritative)

All FAC lane execution state MUST live under `$APM2_HOME/private/fac` so that:
* GC can be enforced coherently
* backup/restore is well-defined
* ambient `$HOME/.cache` sprawl is avoided

Required layout:

* `private/fac/lanes/<lane_id>/workspace/`
* `private/fac/lanes/<lane_id>/target/<toolchain_fingerprint>/`
* `private/fac/lanes/<lane_id>/logs/`
* `private/fac/queue/{pending,claimed,done,cancelled}/`
* `private/fac/receipts/` (content-addressed receipt objects; see §5.3)
* `private/fac/locks/` (lane locks, queue locks, optional global locks)

Legacy compatibility:
* `private/fac/gate_cache_v2/` remains during migration; new receipts MUST record enough to migrate away from it later.

### 5.2 CLI (required commands)

All commands MUST support `--json` for machine output and MUST fail with non-zero exit codes on invariant violations.

#### 5.2.1 `apm2 fac lane status`

Shows all lane states derived from (a) lock state, (b) lease record, (c) last receipt.

* human output: table (lane_id, state, job_id, started_at, toolchain_fingerprint, last_exit)
* json output: array of `LaneStatusV1` objects (schema may be embedded; not required in this amendment)

#### 5.2.2 `apm2 fac lane reset <lane_id>`

Resets a lane to a known-good state.

Rules:
* MUST refuse to reset if lane is RUNNING unless `--force` is provided.
* `--force` MUST stop/kill the lane's active unit (KillMode=control-group) before deletion.
* MUST use `safe_rmtree_v1` for deletion (see §4.7).
* MUST write a `FacJobReceiptV1`-style receipt with `kind="lane_reset"` (or a dedicated `LaneResetReceiptV1`; either is acceptable if schema-id is stable).

#### 5.2.3 `apm2 fac enqueue <job_spec>`

Enqueues a job without executing it immediately.

* `<job_spec>` is a path to a JSON file containing `FacJobSpecV1` OR `-` (stdin).
* on success: prints `job_id` (human) or a JSON object with `{ job_id, queued_path }`

Cancellation (mandatory for queue semantics):
* `apm2 fac enqueue --cancel <job_id>` MUST move the job to `queue/cancelled/` if pending, or mark it cancelled if claimed/running (best-effort signal).

#### 5.2.4 `apm2 fac warm`

Lane-scoped cache warm.

* default: warm **all lanes** to reduce cold-start probability
* `--lane <lane_id>`: warm only one lane
* MUST acquire lane lease(s) internally
* MUST write `WarmReceiptV1`

#### 5.2.5 `apm2 fac gc`

Global and lane-scoped enforced GC.

* default: global GC across all FAC-controlled roots
* `--lane <lane_id>`: only prune that lane's logs/targets
* MUST write `GcReceiptV1`
* MUST be callable automatically from disk preflight (see §6.2)

#### 5.2.6 `apm2 fac gates`

Runs evidence gates using the lane substrate.

Rules:
* MUST acquire a lane lease internally (no "run directly in caller worktree" once Phase 1 is complete)
* MUST use nextest explicitly (no cargo-test fallback)
* MUST fail closed if nextest is missing
* MUST enforce the 240s/24G test policy (no override without explicit unsafe flag)

Queueing:
* `apm2 fac gates --queued` MUST translate into `FacJobSpecV1(kind="gates")` and enqueue, then optionally wait for completion (`--wait` default true).

### 5.3 JSON schemas (required; with hashing rules + storage locations)

All schemas MUST:
* include `schema` (stable ID with version suffix)
* use `#[serde(deny_unknown_fields)]` in implementation
* be bounded in size on read (reuse apm2-core FAC bounded deserialization primitives)

Canonical hashing rules:
* Hash input is canonical JSON bytes (stable key ordering, no insignificant whitespace).
* Hash algorithm for lane/job receipts is **BLAKE3** with domain separation:
  * `hash = blake3("apm2:fac:<schema_id>:v1\0" || canonical_json_bytes)`
* Hashes are encoded as lowercase hex and prefixed: `blake3:<hex>`

Storage rules:
* Each receipt is stored content-addressed:
  * `$APM2_HOME/private/fac/receipts/<hash>.json`
* Queue objects are stored by job_id:
  * `$APM2_HOME/private/fac/queue/pending/<job_id>.json`

#### 5.3.1 `LaneProfileV1`

```jsonc
{
  "schema": "apm2.fac.lane_profile.v1",
  "lane_id": "lane-00",
  "node_fingerprint": "blake3:…",
  "resource_profile": {
    "cpu_quota_percent": 200,
    "memory_max_bytes": 25769803776,
    "pids_max": 1536,
    "io_weight": 100
  },
  "timeouts": {
    "test_timeout_seconds": 240,
    "job_runtime_max_seconds": 1800
  },
  "policy": {
    "fac_policy_hash": "sha256:…",
    "nextest_profile": "ci",
    "deny_ambient_cargo_home": true
  }
}
```

Lane profile storage:
* `$APM2_HOME/private/fac/lanes/<lane_id>/profile.v1.json`

Lane profile hash:
* `LaneProfileHash = blake3(canonical(LaneProfileV1))`

#### 5.3.2 `LaneLeaseV1`

```jsonc
{
  "schema": "apm2.fac.lane_lease.v1",
  "lane_id": "lane-00",
  "job_id": "job_20260212T031500Z_…",
  "pid": 12345,
  "state": "RUNNING",
  "started_at": "2026-02-12T03:15:00Z",
  "lane_profile_hash": "blake3:…",
  "toolchain_fingerprint": "blake3:…"
}
```

Storage:
* `$APM2_HOME/private/fac/lanes/<lane_id>/lease.v1.json`

#### 5.3.3 `FacJobSpecV1`

```jsonc
{
  "schema": "apm2.fac.job_spec.v1",
  "job_id": "job_20260212T031500Z_…",
  "kind": "gates",
  "priority": 50,
  "enqueue_time": "2026-02-12T03:15:00Z",
  "repo_root": "/abs/path/to/apm2",
  "git": {
    "head_sha": "012345…",
    "dirty": false,
    "dirty_diff_hash": null
  },
  "lane_requirements": {
    "lane_profile_hash": null
  },
  "constraints": {
    "require_nextest": true,
    "test_timeout_seconds": 240,
    "memory_max_bytes": 25769803776
  }
}
```

Dirty-tree rule:
* if `dirty=true`, either `dirty_diff_hash` MUST be present and included in attestation OR cache reuse MUST be disabled (fail-closed).

#### 5.3.4 `FacJobReceiptV1`

```jsonc
{
  "schema": "apm2.fac.job_receipt.v1",
  "job_id": "job_…",
  "kind": "gates",
  "lane_id": "lane-00",
  "lane_profile_hash": "blake3:…",
  "toolchain_fingerprint": "blake3:…",
  "fac_policy_hash": "sha256:…",
  "started_at": "…",
  "finished_at": "…",
  "status": "SUCCESS",
  "exit_code": 0,
  "artifacts": {
    "log_bundle_hash": "blake3:…",
    "gate_cache_keys": ["sha256:…"]
  }
}
```

#### 5.3.5 `WarmReceiptV1`

```jsonc
{
  "schema": "apm2.fac.warm_receipt.v1",
  "lane_id": "lane-00",
  "lane_profile_hash": "blake3:…",
  "toolchain_fingerprint": "blake3:…",
  "started_at": "…",
  "finished_at": "…",
  "steps": [
    { "name": "cargo_fetch", "exit_code": 0, "duration_ms": 1234 },
    { "name": "cargo_build", "exit_code": 0, "duration_ms": 5678 }
  ]
}
```

#### 5.3.6 `GcReceiptV1`

```jsonc
{
  "schema": "apm2.fac.gc_receipt.v1",
  "started_at": "…",
  "finished_at": "…",
  "policy": { "min_free_bytes": 21474836480, "min_free_percent": 10 },
  "before": { "free_bytes": 123, "free_percent": 1.2 },
  "after": { "free_bytes": 456, "free_percent": 12.3 },
  "freed_bytes": 333,
  "actions": [
    { "kind": "prune_lane_targets", "lane_id": "lane-01", "freed_bytes": 123 }
  ]
}
```

### 5.4 Attestation integration (fail-closed)

The following MUST be present in gate-cache key material (directly or via digests):

* `LaneProfileHash`
* `ToolchainFingerprint`
* `FacPolicyHash` (authoritative policy version)

Minimum required changes to the current attestation:

* include `.cargo/config.toml` in gate input digests for cargo-based gates
* include `rustfmt --version` in environment facts
* extend command/environment allowlist to include:
  * `CARGO_HOME`, `CARGO_TARGET_DIR`, `CARGO_BUILD_JOBS`, `NEXTEST_TEST_THREADS`
  * `RUSTC_WRAPPER` and `SCCACHE_*` (future-proof; no effect when unset)

Policy hashing:

* define a single authoritative `FacPolicyV1` in Rust (and optionally emitted to `$APM2_HOME/private/fac/policy/fac_policy.v1.json` for inspection)
* `FacPolicyHash = sha256(canonical_json(FacPolicyV1))`
* any change to timeouts, resource caps, allowlists, or tool requirements MUST change `FacPolicyHash`

---

## 6. Enforced hygiene: disk preflight + GC (cannot be optional)

### 6.1 Disk preflight (mandatory gate before heavy jobs)

Before a job enters RUNNING, the scheduler MUST:

1. compute free space for:
   * filesystem containing the lane workspace
   * filesystem containing `$APM2_HOME`
2. compare against policy (`min_free_bytes` AND `min_free_percent`)
3. if below threshold:
   * run `apm2 fac gc` in enforcement mode
   * re-check
4. if still below threshold:
   * FAIL CLOSED (do not start the job; host is at risk)

Default policy for the current node class:
* `min_free_bytes = 20 GiB`
* `min_free_percent = 10%`

### 6.2 What GC is allowed to delete (explicit allowlist)

GC MAY delete only:
* lane targets under `private/fac/lanes/*/target/*` (excluding leased/running lanes)
* lane logs under `private/fac/lanes/*/logs` beyond retention/quota
* FAC evidence logs under `private/fac/evidence` beyond retention/quota
* (optional) gate cache entries beyond TTL (legacy)
* (future) sccache dirs under FAC-controlled roots, if enabled

GC MUST NOT delete:
* identity/keys under `$APM2_HOME/private` that are not explicitly marked as FAC cache
* git worktrees themselves outside FAC lane roots

All deletions MUST use `safe_rmtree_v1`.

---

## 7. Migration plan (staged, rollbackable)

This is the incremental deployment plan required by the prompt.

### Phase 0 — Instrumentation + invariants (no behavior change)

Deliverables:
* add missing fail-closed attestation inputs (`.cargo/config.toml`, `rustfmt --version`)
* remove cargo-test fallback for FAC tests; nextest required (fail fast if missing)
* add dirty-tree protection (disable cache or incorporate diff digest)
* add disk preflight checks (warn-only at first; no GC yet)

Acceptance criteria:
* no regressions to existing `apm2 fac gates` UX on a healthy machine
* cache keys change when `.cargo/config.toml` changes

Rollback:
* single PR revert (no persistent state changes required)

### Phase 1 — Local lanes + lane leases + target namespaces (single VPS)

Deliverables:
* implement `LaneProfileV1`, deterministic `lane_id` set (default 3 lanes on this box)
* implement lane lease locks + lease records
* implement per-lane `CARGO_TARGET_DIR` under lane target namespace
* implement `apm2 fac lane status`
* implement `apm2 fac gates` acquiring a lane lease internally

Acceptance criteria:
* three concurrent `apm2 fac gates` invocations never exceed lane count
* target reuse collapses disk usage vs many worktrees (qualitative)

Rollback:
* `APM2_FAC_LANES=0` (or `--legacy`) runs old path; lane directories remain but are inert

### Phase 2 — Queueing + priority + cancellation + lane reset + enforced GC

Deliverables:
* implement filesystem job queue (`pending/claimed/done/cancelled`)
* implement `apm2 fac enqueue` and `apm2 fac gates --queued`
* implement `apm2 fac lane reset` with symlink-safe deletion
* turn disk preflight from warn-only to enforced (auto GC, fail closed if still low)
* implement `apm2 fac gc` + `GcReceiptV1`

Acceptance criteria:
* enqueue + cancellation works correctly under concurrent clients
* disk preflight demonstrably prevents "disk full mid-build" failures in normal operation

Rollback:
* disable queue consumption; run direct lane acquisition mode

### Phase 3 — Assimilate second VPS (Nix + flakes) with minimal interop seam

Deliverables:
* "assimilate node" playbook:
  * clone repo at pinned commit
  * `nix develop`
  * restore minimal `$APM2_HOME` state (receipts, configs, keys; not bulky caches)
  * run `apm2 fac warm` to rehydrate caches
* local scheduler per host; no distributed routing required
* define a transport-agnostic evidence bundle export/import contract (see §8)

Acceptance criteria:
* catastrophic failure recovery on primary host is reproducible within a single playbook run
* developer shell/toolchain parity achieved via flakes

Rollback:
* none; this is additive documentation + optional tooling

### Phase 4 — 100+ nodes (design only): distributed routing + receipt stream merge

Deliverables:
* stable job spec + receipt schemas sufficient for routing without semantic refactor
* define trust boundaries + authentication using PCAC/AJC (no implementation)

---

## 8. Evidence bundle streaming seam (contract; no networking implementation)

### 8.1 Evidence bundle contents (build success / failure)

An evidence bundle is a content-addressed set with a manifest:

* `FacJobReceiptV1`
* gate attestation objects referenced by hash
* logs (possibly compressed) referenced by hash
* optional artifacts (binary size summaries, nextest junit, etc.) referenced by hash

### 8.2 Hashing + addressing

* each blob is addressed by `blake3:<hex>`
* manifest schema (proposed): `apm2.fac.evidence_bundle_manifest.v1`
* bundle id = blake3(canonical(manifest))

### 8.3 Transport-agnostic envelope

Define an envelope format that can be shipped later over any transport:

* `schema: apm2.fac.evidence_bundle_envelope.v1`
* `bundle_id`
* `compression` (none|zstd)
* `chunks[]` (each chunk references a blob hash)

No networking code is defined here; only the object contract.

### 8.4 Receipt stream merge (CRDT-ish)

Receipt streams MUST be mergeable by set union:

* receipts are immutable content-addressed objects
* stream merge = union of receipt hashes + deterministic ordering for presentation using HLC-with-node-id (see apm2-core consensus CRDT primitives)

### 8.5 Authentication boundary (future PCAC/AJC seam)

Future distributed mode MUST authenticate:

* which node produced the bundle (node identity)
* which capabilities authorized job execution (PCAC/AJC chain)

In v1 (local-only), these fields may be present but unsigned; v2 adds signatures without changing schema semantics.

---

## 9. Nextest policy: stop relying on ambient aliasing

### 9.1 Explicit recommendation

**Do not alias `cargo test` → nextest** as part of the canonical FAC substrate.

Reasons (practical, not ideological):

* It is an **ambient global mutation** of tooling semantics that your attestation cannot reliably see (unless you treat `~/.cargo/config.toml` as a formal input, which you should not).
* It can break commands that expect `cargo test` semantics (including compile-only patterns like `cargo test --no-run`, or third-party scripts that assume cargo behavior).
* It undermines the "instantly reproduce environment across VPSs" objective; you will forget one node or one systemd unit will not pick up shell alias state.

### 9.2 What we do instead (mandatory, encoded)

**FAC test execution uses nextest explicitly** in the code path.

Concrete repo changes:

* In `crates/apm2-cli/src/commands/fac_review/evidence.rs` (pipeline path) and in `crates/apm2-cli/src/commands/fac_review/gates.rs` (local gates path):

  * Replace **all** non-bounded fallbacks from `cargo test --workspace` to:

    * `cargo nextest run --workspace --all-features --config-file .config/nextest.toml --profile ci`
  * If nextest is missing in any scenario, fail with a clear error that nextest is required for FAC gates (FAC substrate mandate).

This turns nextest into a **declared dependency** of the FAC substrate, consistent with `flake.nix` already including `cargo-nextest`.

Missing-but-required detail: align nextest's own concurrency knobs with the global governor:

* `NEXTEST_TEST_THREADS` must be set (or `--test-threads`) to match the per-slot CPU budget, otherwise you still get oversubscription even with CPUQuota.

### 9.3 Optional dev convenience (safe)

If you want a shortcut, add a **non-overriding** cargo alias (repo-local, not user-global):

* In `.cargo/config.toml` add:

```toml
[alias]
nt = "nextest run --workspace --all-features --config-file .config/nextest.toml --profile ci"
```

Key: **do not override `test`**. Provide a new alias.

---

## 10. Build cache substrate: target pool (primary), sccache (optional)

### 10.1 Primary accelerator: slot-scoped `CARGO_TARGET_DIR` ("target pool")

Why this exists:

* The dominant real-world cost in your described regime is **duplicated `target/` trees** across worktrees.
* RFC-0007 rejected a global shared `CARGO_TARGET_DIR` because cargo uses a target-dir lock that prevents parallel builds.
* This amendment introduces a global concurrency governor (compute slots). **Once you have slots, you can have "N target dirs"**:
  * each slot has its own target dir
  * at most one heavy build runs per slot
  * parallelism is preserved up to N without cargo lock contention

Policy:

* Every "heavy" FAC operation (gates, pipeline evidence, warm) acquires a compute slot.
* On slot acquisition, FAC sets:
  * `CARGO_TARGET_DIR=$APM2_HOME/private/fac/target_pool/<toolchain_fingerprint>/slot_<i>`
  * `CARGO_BUILD_JOBS=<computed>`
  * `NEXTEST_TEST_THREADS=<computed>`
* FAC must **override** any ambient `CARGO_TARGET_DIR` rather than inheriting it.

Result:

* Cross-worktree reuse of compiled dependencies without sccache.
* Disk usage collapses from "~13 targets" to "≤ slot_count targets".
* No new daemon boundary, so containment is straightforward.

### 10.2 Security boundary alignment (TB-002)

RFC-0007 TB-002 already establishes:

* Compilation cache is local, trusted
* Remote caches are not assumed safe

This amendment enforces:

* target pool directories are under explicit control (`$APM2_HOME/private/fac/target_pool`)
* they are subject to GC policy
* optional sccache use is local-only and explicitly controlled (if/when enabled)

### 10.3 Optional secondary accelerator: sccache (only if it actually helps)

We choose the **explicit-activation model** for sccache (if/when implemented):

* `apm2` commands decide when to use sccache
* We do **not** make sccache an always-on implicit requirement by hardcoding `build.rustc-wrapper="sccache"` in `.cargo/config.toml`

Rationale:

* `.cargo/config.toml` is always present; making it require sccache causes a hard failure on any node missing sccache.
* More importantly, FAC runs under bounded systemd units; implicit wrappers are harder to reason about and attest.
* Explicit activation makes it possible to:

  * run "safe mode" (no sccache) if needed for debugging
  * record activation in receipts and attestation
  * migrate to NixOS without hidden assumptions

### 10.4 Standard cache locations

We standardize:

* `FAC_TARGET_POOL_ROOT = $APM2_HOME/private/fac/target_pool`
* `CARGO_TARGET_DIR = $FAC_TARGET_POOL_ROOT/<toolchain_fingerprint>/slot_<i>`

If sccache is enabled later:

* `SCCACHE_DIR = $APM2_HOME/private/cache/sccache`

Why under APM2_HOME?

* makes GC and backup policy coherent
* avoids scattered caches across `$HOME/.cache`
* makes "restore environment on new VPS" more predictable

Implementation note:

* `apm2_home_dir()` already exists in `fac_review/types.rs`; use it to derive the path.

### 10.5 Critical containment caveat: sccache + cgroups

This is where the original planning doc was dangerously under-specified.

Because the test gate is executed under a bounded `systemd-run` unit, we must assume:

* any compilation or compilation-adjacent process must remain inside the bounded cgroup to preserve the 24G/240s guarantees.

**Risk:** If sccache uses a long-lived daemon that spawns compiler processes outside the transient unit cgroup, your "bounded tests" aren't actually bounded. That is an unacceptable integrity regression.

**Mitigation policy in this amendment:**

* Default stance: **do not enable sccache inside bounded units** until proven safe and beneficial.

If/when you try to enable it:

* You must ensure the sccache server that spawns compiler processes is inside the unit cgroup.
* The earlier draft conflated `SCCACHE_NO_DAEMON` with "no server". In sccache, `SCCACHE_NO_DAEMON=1` only prevents daemonization (it does not eliminate the server boundary).
* A safer pattern (if needed) is: start the server inside the unit (`sccache --start-server`), and stop it when the unit finishes (`sccache --stop-server`) while ensuring it cannot connect to an already-running out-of-cgroup server (e.g., via per-unit socket config).

Otherwise, keep sccache off for bounded units and rely on:

* target pool reuse + warm/prebuild (see §11)

Because sccache behavior may differ by version, this amendment requires a **verification check** (see §15) that confirms rustc processes remain inside the bounded cgroup when sccache is enabled.

If verification fails, the "safe fallback" is:

* **do not enable sccache inside bounded units**
* rely on pre-warm compilation outside bounded units to keep bounded test runs as "run-only" as possible

This is not optional hand-waving; it is the containment guarantee.

### 10.6 Attestation surfacing

We must make cache substrate visible to the gate attestation so cache reuse is fail-closed.

Changes:

1. **Add `.cargo/config.toml` to `gate_input_paths`** for all cargo-based gates in `gate_attestation.rs`:

   * `rustfmt`, `clippy`, `doc`, `test` should all include `.cargo/config.toml` as an input
   * Rationale: cargo behavior can be influenced by repo-local config; attestation must see it

2. **Fix existing fail-open first, then extend**:

   * Add `rustfmt --version` to `environment_facts` (fmt gate correctness can change across toolchain updates).

3. **Add env vars to `command_digest` allowlist** (future-proof; harmless when unset):

   * `RUSTC_WRAPPER`
   * `SCCACHE_DIR`
   * `SCCACHE_CACHE_SIZE` (if we set it)
   * `SCCACHE_NO_DAEMON` (if we set it)
   * (Optional) `SCCACHE_LOG` / `SCCACHE_ERROR_LOG` if used; otherwise omit

4. **Add sccache version to `environment_facts`** (only matters when sccache is enabled; still safe to record if present):

   * record `sccache --version` output (if present)
   * If sccache becomes required for any FAC profile, absence must fail the invoking FAC command (not just "string = unavailable").

---

## 11. `apm2 fac warm`: pre-warming as a first-class, attested maintenance action

### 11.1 Why warm is required (and where it belongs)

Given the "240s/24G bounded test SLA," we treat warm as:

* a **worktree lifecycle step**, not a per-run step
* required:

  * on fresh worktree creation
  * after toolchain upgrades (rustc/cargo changes)
  * after aggressive GC/cargo clean

Warm is how we turn bounded tests into "run-only" rather than "build + run."

### 11.2 CLI interface

Add to `crates/apm2-cli/src/commands/fac.rs`:

```rust
/// Pre-warm compilation caches for FAC evidence gates.
Warm(WarmArgs),
```

Proposed args (minimum viable + future-proof):

* `--json` already supported by root
* `WarmArgs`:

  * `--phases fetch,build,clippy,doc` (default: `fetch,build,clippy,doc`)
  * `--jobs <N>` (optional override; otherwise computed)
  * `--no-target-pool` (debug-only escape hatch; uses per-worktree `target/` and will be slower)
  * (future) `--sccache` / `--no-sccache` only if/when sccache is implemented
  * `--bounded` (optional: run warm under a resource governor scope; default true on multi-agent boxes)

### 11.3 Execution plan

Warm runs these phases (with timing):

1. `cargo fetch --locked`
2. `cargo build --workspace --all-targets --all-features --locked` (optional; see phase selection)
3. `cargo nextest run --workspace --all-features --config-file .config/nextest.toml --profile ci --no-run`
4. (optional) `cargo clippy ...`
5. (optional) `cargo doc ...`

All commands run with:

* target pool enabled by default (`CARGO_TARGET_DIR` set by the acquired compute slot)
* `CARGO_BUILD_JOBS = computed_or_override`
* `NEXTEST_TEST_THREADS = computed_or_override`
* (future) sccache env only if enabled

### 11.4 Warm locking and concurrency

Warm must not stampede, but **do not serialize warm globally**: global warm locks reduce throughput and create single-point deadlocks.

Instead:

* warm acquires a compute slot; that is the concurrency control.
* per-slot target pool already eliminates "13 worktrees compiling 13 times" — the stampede surface is drastically reduced.

Behavior:

* If no compute slots are available:
  * default: wait (bounded by a reasonable max, or with `--no-wait` to fail fast)

### 11.5 Warm receipts

Warm must write a durable receipt:

* Path: `$APM2_HOME/private/fac/maintenance/warm/<ts>_<sha256>.json`
* Schema: `apm2.fac.warm_receipt.v1`

Suggested fields:

```jsonc
{
  "schema": "apm2.fac.warm_receipt.v1",
  "workspace_root": "/abs/path",
  "git_head_sha": "abc123...",
  "started_at": "2026-02-11T...",
  "finished_at": "2026-02-11T...",
  "phases": [
    { "name": "fetch", "cmd": "...", "exit_code": 0, "duration_ms": 1234 },
    { "name": "build", "cmd": "...", "exit_code": 0, "duration_ms": 5678 },
    ...
  ],
  "tool_versions": {
    "rustc": "...",
    "cargo": "...",
    "clippy": "...",
    "nextest": "...",
    "sccache": "..."
  },
  "sccache": {
    "dir": "...",
    "cache_size_policy": "...",
    "stats": "raw output or parsed summary"
  }
}
```

This receipt is intentionally similar in spirit to FAC receipts: structured, auditable, machine-ingestible.

---

## 12. Resource hygiene: `apm2 fac gc` as an enforced safety valve

### 12.1 Why GC must exist as a FAC primitive

You have:

* many worktrees
* large `target/` dirs
* parallel agents
* a strict "host must remain functional" requirement

Therefore GC cannot remain an informal human action.

Also missing from the draft: "GC as a manual command" does not satisfy the stated goal of **automatic and enforced cleanup**.
This amendment therefore requires:

* enforced disk preflight in `gates`, `warm`, and pipeline evidence
* GC auto-invocation when below `min-free`

### 12.2 CLI interface

Add:

* `apm2 fac gc` (maintenance command)

Args:

* `--json`
* `--dry-run`
* `--min-free <SIZE|PERCENT>` (default policy: see below)
* `--keep-hot-worktrees <N>` (default: derived from concurrency)
* `--ttl-days <D>` for "cold worktree targets"
* `--sccache-trim` (default true)
* `--gate-cache-ttl-days <D>` (default: 30)
* `--aggressive` (enables deeper deletions)

### 12.3 What GC is allowed to delete (safe set)

GC is allowed to delete:

1. Worktree-local `target/` directories for "cold" worktrees (legacy artifacts once target pool is enabled)
2. Target-pool slot directories that are not currently leased (LRU policy) **if disk preflight still fails after pruning cold worktrees**
3. `$APM2_HOME/private/cache/sccache` directory (delete as a last resort) if sccache is enabled
4. `$APM2_HOME/private/fac/gate_cache_v2` entries beyond TTL (optional; low ROI but safe)
5. Any **known scratch** artifacts (e.g., `target/ci/**` snapshots) as part of deleting target dirs

GC must **not** delete:

* keys / identity material under `$APM2_HOME/private/*` unless explicitly in a separate "nuke" command
* git worktrees themselves (only their build artifacts)

### 12.4 "Active worktree" definition

A worktree is **active** if any of the following are true:

* It is the current working directory of the invoking process (obviously)
* It has a live FAC lock lease file (see §13)
* It has a running `systemd-run` unit associated with it (optional detection)
* It has been used recently (mtime heuristic):

  * any file under worktree `.git` metadata updated recently
  * OR last warm receipt references it within TTL window

Everything else is eligible for target pruning.

Required amendment: "active" must be defined in terms of the actual global governor, not heuristics.

* A worktree is active iff it is referenced by an active compute-slot lease record (see §13.2.3).
* Heuristics (mtime) may be used as a fallback only when lease metadata is missing.

### 12.5 Default policy for your current box

Given 96GB RAM and up to 3 simultaneous gate executions:

* **Keep-hot-worktrees:** 3
* **Cold worktree TTL:** 7 days (targets older than this are prunable)
* **Min free disk:** `max(20 GiB, 10%)` on the filesystem containing the repo roots
  (use both: a percent for big disks, a floor for small disks)

If min-free is violated:

* GC must escalate in layers:

  1. prune cold worktree targets
  2. trim sccache to target size
  3. prune old gate cache entries
  4. if still below min-free: **fail with a hard error** (host is at risk)

Missing detail: enforce on both relevant mounts.

* Evaluate `min-free` for the filesystem containing `workspace_root`.
* Evaluate `min-free` for the filesystem containing `$APM2_HOME`.
* The preflight passes only if both pass, because disk-full on either breaks FAC.

### 12.6 GC receipts

GC writes:

* `$APM2_HOME/private/fac/maintenance/gc/<ts>_<sha256>.json`
* Schema: `apm2.fac.gc_receipt.v1`

Include:

* disk free before/after
* bytes freed by category
* list of deleted directories (or hashes, if you want to avoid path disclosure)
* policy parameters used

---

## 13. Global resource governor: stop pretending per-command limits are sufficient

### 13.1 The missing control plane

Today, only the test gate is bounded by `systemd-run`. That does not provide "host survivability" under multiple agents.

This amendment introduces a minimal, incremental control plane:

* A local **compute lease** system (file-lock-based) that limits concurrent heavy operations.

### 13.2 Compute lease model (Phase 1)

Implement a token semaphore under:

* `$APM2_HOME/private/fac/locks/compute_slot_<i>.lock` for i ∈ [0, N)

Do not invent this from scratch: the repo already has a proven pattern for "slot leasing via file locks"
(`fac_review/model_pool.rs::acquire_provider_slot`). Reuse that approach (jitter, timeout, RAII guard).

Default N computed as:

* `N = min(3, floor((total_mem_gib - reserve_gib) / mem_per_gate_gib))`

  * reserve_gib default: 20
  * mem_per_gate_gib default: 24 (aligned with bounded tests)

For your box, N should evaluate to 3.

Any heavy operation must acquire a slot:

* `apm2 fac gates` (full mode)
* `apm2 fac warm`
* `apm2 fac pipeline` evidence phase (background push/restart path)
* `apm2 fac gc` when invoked in enforcement mode (preflight-triggered), because it competes for IO

Lease is held for the duration; released on exit (Drop guard).

### 13.2.3 Lease metadata (required for GC safety + debugging)

On acquisition, write a sidecar JSON (not locked, but best-effort, overwrite-safe):

* `$APM2_HOME/private/fac/locks/compute_slot_<i>.json`

Fields:

* pid
* command (gates/warm/pipeline/gc)
* workspace_root
* started_at
* toolchain_fingerprint (see §10.1)

This single mechanism prevents:

* 10 agents all running clippy/doc simultaneously
* warm stampedes
* silent death-by-IO

### 13.3 Compute-aware `CARGO_BUILD_JOBS` (Phase 1)

When a process acquires a compute slot, it computes a default `CARGO_BUILD_JOBS`:

Inputs:

* CPU count
* acquired slot index (not required, but useful)
* total concurrent slots N
* per-slot CPU quota target

Policy:

* `jobs = clamp(2, floor(cpu_count / N), 12)` (raise the cap; 8 is an unjustified throttle on typical 24–64 core VPS nodes)

This is intentionally conservative on 96GB: it trades a small amount of peak speed for avoiding memory spikes and IO contention.

Missing-but-required: nextest runtime concurrency alignment:

* `NEXTEST_TEST_THREADS = clamp(1, floor(cpu_count / N), 8)` (separate from build jobs; prioritize host responsiveness)

Optional: if bounded tests keep CPUQuota, compute CPUQuota from CPU count and N instead of hardcoding `200%`.

### 13.4 Phase 2: long-lived "FAC Execution Pool" (the thing you're gesturing at)

You asked whether "1 worktree = 1 ticket" is the right primitive. For exabyte/100B-agent scale, it isn't.

This amendment defines the target architecture:

* A local **FAC Execution Pool (FEP)** with:

  * **N long-lived slots**
  * each slot is a *cullable, instantly refreshable* execution context
  * each slot has:

    * a dedicated worktree root (or ephemeral checkout)
    * a dedicated target dir
    * optionally, a dedicated sccache server if needed for containment

Agents request a slot lease; the slot runs gates inside its preconfigured cgroup/slice.

Why this matters:

* the pool becomes the natural place to integrate:

  * systemd slice budgets
  * per-slot and global disk quotas
  * sccache containment rules
  * fast "reset slot" on corruption

This is the correct "control surface" for scaling to many nodes and many agents. Phase 1 leases are the minimal stepping stone.

---

## 14. Nix integration: environment must be declarative

### 14.1 flake.nix updates

`flake.nix` already includes `cargo-nextest`. This amendment requires adding:

* (optional) `sccache` only if/when we decide to ship it as part of the FAC substrate

This amendment does require:

* nothing new for the target pool (it's policy + env)

so the dev shell is a complete reproduction unit for FAC warm/gates.

### 14.2 Backup/restore implications

Because you have a backup node on the same headscale network:

* treat caches as *optional accelerants*, not required state
* back up:

  * `$APM2_HOME` excluding bulky caches by default
  * include:

    * FAC receipts (gate cache + maintenance receipts)
    * config files
    * keys / identity material (with appropriate protection)
* optionally back up:

  * sccache dir (large, but can accelerate restore)
  * cargo registry cache (also large)

The "instant reproduction" story should be:

1. clone repo at known commit
2. `nix develop` (tools pinned)
3. restore `$APM2_HOME` minimal set
4. run `apm2 fac warm`

---

## 15. Verification and hard checks

This amendment is only acceptable if these checks pass.

### 15.1 Functional checks

1. `nix develop` provides:

   * `cargo nextest` available
   * (optional) `sccache` available if enabled

2. `apm2 fac warm`:

   * produces receipt
   * produces target-pool artifacts (slot target dir size increases; subsequent gates are faster)
   * respects compute slots (no stampede, no global warm lock)

3. `apm2 fac gates` (full mode):

   * after warm, test gate completes within 240s and does not OOM under 24G
   * produces gate cache receipts

4. Attestation tests remain stable and fail-closed:

   * changing `.cargo/config.toml` changes input digest (cargo gates)
   * changing rustfmt version changes environment digest (fmt gate)
   * (if enabled) changing `RUSTC_WRAPPER` changes attestation digest

### 15.2 Containment check (mandatory)

If we enable sccache inside bounded units, we must verify:

* rustc processes spawned during bounded tests are inside the same cgroup as the systemd-run unit.

A practical check:

* During a bounded test run, capture cgroup path of the main process and of a rustc child.
* If mismatch → **disable sccache inside bounded units** and rely on warm/prebuild.

This check can be implemented as:

* a test harness script
* or a debug mode in `run_bounded_tests.sh` / Rust replacement later

---

## 16. Concrete file-level deltas (amendment plan)

### 16.1 Code changes

* `crates/apm2-cli/src/commands/fac.rs`

  * add `Warm(WarmArgs)` and `Gc(GcArgs)` subcommands
  * route to `fac_review::{warm,gc}::run_*`

* `crates/apm2-cli/src/commands/fac_review/`

  * new: `warm.rs` (implements warm, receipts, locks)
  * new: `gc.rs` (implements policy, receipts, pruning)
  * new: `fac_resources.rs` (compute slots + disk preflight helpers; reuse existing slot leasing patterns)
  * new: `target_pool.rs` (derive toolchain fingerprint + slot target dir path)
  * modify: `gate_attestation.rs`

    * include `.cargo/config.toml` in input digests for cargo gates
    * add rustfmt version to environment facts
    * (future) allowlist env vars (`RUSTC_WRAPPER`, `SCCACHE_*`)
  * modify: `evidence.rs`

    * nextest fallback: remove `cargo test` fallback; prefer nextest always (pipeline + local)
    * ensure pipeline and local gates share a single "build test command" helper
    * optionally add env plumbing to run cargo gates with computed `CARGO_BUILD_JOBS` and sccache env
    * set `NEXTEST_TEST_THREADS` for bounded tests (propagate through allowlist)

* `crates/apm2-cli/src/commands/fac_review/gates.rs`

  * enforce I1 (timeout cap) and other resource caps unless unsafe override
  * ensure non-bounded test path still uses nextest
  * acquire compute slot for the entire gates run and set env (`CARGO_TARGET_DIR`, etc.) once

* `scripts/ci/run_bounded_tests.sh`

  * extend env propagation allowlist to include:

    * `CARGO_BUILD_JOBS`
    * `CARGO_TARGET_DIR`
    * `NEXTEST_TEST_THREADS`
    * `RUSTUP_TOOLCHAIN` (align with attestation allowlist)

* `flake.nix`

  * add `sccache` to devShell packages only if we decide to ship it as part of FAC substrate

* `documents/skills/implementor-default/SKILL.md`

  * add CACHE_WARM (or equivalent) node as a lifecycle step after worktree prep and before editing

### 16.2 RFC-0007 doc changes

Update `documents/rfcs/RFC-0007/02_design_decisions.yaml`:

* Replace "optional nextest" decisions with:

  * **FAC substrate mandates nextest** (explicit invocation)
  * cargo test aliasing is not relied upon

Update `documents/rfcs/RFC-0007/03_trust_boundaries.yaml` TB-002:

* Add containment requirement language (bounded units)
* Add requirement that cache dir is under APM2_HOME and subject to GC policy

Add a new section (or amendment file) describing:

* warm and GC interfaces
* compute lease concept
* Nix reproduction

---

## 17. Ticket YAMLs (drop-in proposals)

Below are proposed new tickets using the current ticket schema (`schema_version: "2026-01-29"`). IDs start from `TCK-00503` (next available after existing tickets).

Required correction: the original draft omitted a ticket for "mandate nextest everywhere" and conflated sccache with the primary acceleration lever.
This amendment adds an explicit ticket for nextest mandate and moves "cross-worktree reuse" to the target pool.

### TCK-00503 — Add `apm2 fac warm` command with receipts + compute-slot integration

```yaml
ticket_meta:
  schema_version: "2026-01-29"
  template_version: "2026-01-29"
  ticket:
    id: "TCK-00503"
    title: "Implement `apm2 fac warm` pre-warm command with receipt (compute-slot + target pool)"
    status: "OPEN"
  binds:
    prd_id: "PRD-0009"
    rfc_id: "RFC-0007"
    requirements: []
    evidence_artifacts: []
  custody:
    agent_roles: ["AGENT_IMPLEMENTER"]
    responsibility_domains: ["DOMAIN_RUNTIME", "DOMAIN_SECURITY"]
  dependencies:
    tickets:
      - ticket_id: "TCK-00506"
        reason: "Warm must acquire a compute slot and use the target pool; do not implement a second locking scheme."
  scope:
    in_scope:
      - "Add `apm2 fac warm` subcommand routed via crates/apm2-cli/src/commands/fac.rs."
      - "Acquire a FAC compute slot for warm (reuse compute-slot leasing from TCK-00488)."
      - "Enable target pool by default (CARGO_TARGET_DIR derived from slot + toolchain fingerprint)."
      - "Implement warm phases (selectable): cargo fetch --locked; cargo build --workspace --all-targets --all-features --locked; cargo nextest run ... --no-run; optional clippy/doc phases."
      - "Set CARGO_BUILD_JOBS and NEXTEST_TEST_THREADS from compute-slot policy unless explicitly overridden."
      - "Write warm receipt under $APM2_HOME/private/fac/maintenance/warm/ with schema apm2.fac.warm_receipt.v1."
      - "Do NOT add a global warm lock; compute slots are the stampede control."
    out_of_scope:
      - "Distributed cache or remote build farm."
      - "Replacing run_bounded_tests.sh."
  plan:
    steps:
      - "Add FacSubcommand::Warm and WarmArgs in fac.rs and route to fac_review::warm::run_warm."
      - "Implement warm.rs: phase runner with timings, env injection (target pool + jobs + test threads), receipt writer."
      - "Add JSON output mode and human output mode."
      - "Run fmt/clippy/doc/nextest checks."
  definition_of_done:
    evidence_ids: []
    criteria:
      - "`apm2 fac warm` succeeds on a clean main branch and writes a receipt."
      - "Warm respects compute-slot capacity (concurrent warm invocations block or fail fast according to flags)."
      - "Warm increases target-pool artifact reuse: running `apm2 fac gates` immediately after warm is measurably faster than a cold run (qualitative confirmation acceptable initially)."
  notes:
    security: |
      Warm must not read secrets or propagate uncontrolled env into subprocesses beyond
      an allowlist. Receipt must not include credentials.
    verification: |
      Manual: run apm2 fac warm twice; second run should be faster. Confirm that CARGO_TARGET_DIR is under APM2_HOME/private/fac/target_pool.
```

### TCK-00504 — Attestation surfacing for sccache + include `.cargo/config.toml` in input digests

```yaml
ticket_meta:
  schema_version: "2026-01-29"
  template_version: "2026-01-29"
  ticket:
    id: "TCK-00504"
    title: "Fail-closed attestation: include .cargo/config.toml + rustfmt version; future-proof sccache env"
    status: "OPEN"
  binds:
    prd_id: "PRD-0009"
    rfc_id: "RFC-0007"
    requirements: []
    evidence_artifacts: []
  custody:
    agent_roles: ["AGENT_IMPLEMENTER"]
    responsibility_domains: ["DOMAIN_SECURITY", "DOMAIN_RUNTIME"]
  dependencies:
    tickets: []
  scope:
    in_scope:
      - "Update gate_input_paths to include .cargo/config.toml for cargo-based gates (rustfmt/clippy/doc/test)."
      - "Add rustfmt --version to environment_facts (environment_digest) to eliminate fmt-gate fail-open across toolchain updates."
      - "(Future-proof) Update command_digest allowlist to include RUSTC_WRAPPER and SCCACHE_* env vars (harmless when unset)."
      - "(Optional) Add sccache --version to environment_facts (record if present; do not make mandatory unless a FAC profile requires it)."
      - "Add/adjust tests to ensure digests change when cargo config changes and when rustfmt version changes (fail-closed)."
    out_of_scope:
      - "Expanding environment_digest to every tool on the machine."
  plan:
    steps:
      - "Modify allowlisted env array in command_digest()."
      - "Modify gate_input_paths() to include .cargo/config.toml."
      - "Extend environment_facts() to include sccache version."
      - "Run existing attestation tests and update expected digests accordingly."
  definition_of_done:
    evidence_ids: []
    criteria:
      - "Attestation digest changes when RUSTC_WRAPPER changes."
      - "Attestation digest changes when .cargo/config.toml changes."
      - "Attestation digest changes when rustfmt version changes."
      - "No gate cache reuse occurs across these changes."
```

### TCK-00505 — Implement `apm2 fac gc` with enforced disk preflight (worktree targets + target pool + caches)

```yaml
ticket_meta:
  schema_version: "2026-01-29"
  template_version: "2026-01-29"
  ticket:
    id: "TCK-00505"
    title: "Implement `apm2 fac gc` with enforced disk preflight (worktree targets + target pool + caches)"
    status: "OPEN"
  binds:
    prd_id: "PRD-0009"
    rfc_id: "RFC-0007"
    requirements: []
    evidence_artifacts: []
  custody:
    agent_roles: ["AGENT_IMPLEMENTER"]
    responsibility_domains: ["DOMAIN_RUNTIME", "DOMAIN_SECURITY"]
  dependencies:
    tickets: []
  scope:
    in_scope:
      - "Add `apm2 fac gc` subcommand producing a deterministic plan and optional enforcement."
      - "Implement disk preflight helper (min-free) used by gates/warm/pipeline to auto-invoke gc when below threshold."
      - "Enumerate git worktrees and delete target/ dirs for cold worktrees (policy: keep hot N, TTL days)."
      - "If target pool is enabled: delete target-pool slot dirs that are not currently leased (LRU policy) when disk is still below min-free after pruning cold worktrees."
      - "(Optional) If sccache is enabled: delete SCCACHE_DIR as a last resort (do not rely on non-existent `sccache --trim`)."
      - "Write gc receipt under $APM2_HOME/private/fac/maintenance/gc/ with schema apm2.fac.gc_receipt.v1."
      - "Support --dry-run and --json."
    out_of_scope:
      - "Deleting worktrees or branches."
      - "Backing up state to the headscale peer (separate ticket)."
  plan:
    steps:
      - "Define GC policy defaults (min-free, ttl-days, keep-hot-worktrees)."
      - "Implement worktree enumeration and target pruning."
      - "Implement target-pool pruning logic using compute-slot lease metadata (do not delete leased slots)."
      - "Implement receipt writer + dry-run mode."
      - "Add a basic integration test for plan generation (unit test style)."
  definition_of_done:
    evidence_ids: []
    criteria:
      - "`apm2 fac gc --dry-run` prints a coherent plan without side effects."
      - "`apm2 fac gc` reclaims space by deleting cold worktree targets."
      - "Receipt is written and includes bytes freed."
  notes:
    security: |
      GC must never delete identity material. Only delete explicitly permitted cache paths.
      MUST protect against symlink traversal: only delete canonical paths under allowed roots, and refuse if any path component is a symlink.
```

### TCK-00506 — Compute lease semaphore + target pool substrate (cap concurrency, reuse builds)

```yaml
ticket_meta:
  schema_version: "2026-01-29"
  template_version: "2026-01-29"
  ticket:
    id: "TCK-00506"
    title: "Add FAC compute slots + target pool substrate (cap concurrency, reuse builds across worktrees)"
    status: "OPEN"
  binds:
    prd_id: "PRD-0009"
    rfc_id: "RFC-0007"
    requirements: []
    evidence_artifacts: []
  custody:
    agent_roles: ["AGENT_IMPLEMENTER"]
    responsibility_domains: ["DOMAIN_RUNTIME"]
  dependencies:
    tickets: []
  scope:
    in_scope:
      - "Introduce file-lock-based compute slots under $APM2_HOME/private/fac/locks/compute_slot_<i>.lock."
      - "Acquire a slot for apm2 fac warm, apm2 fac gates (full mode), and pipeline evidence execution."
      - "Use slot count default derived from memory policy (96GB -> 3 slots)."
      - "Compute conservative default CARGO_BUILD_JOBS based on cpu_count / slots."
      - "Set NEXTEST_TEST_THREADS based on cpu_count / slots to prevent runtime oversubscription."
      - "Implement slot metadata sidecar ($APM2_HOME/private/fac/locks/compute_slot_<i>.json) for GC safety + debugging."
      - "Implement target pool: on slot acquisition set CARGO_TARGET_DIR=$APM2_HOME/private/fac/target_pool/<toolchain_fingerprint>/slot_<i> (override any ambient CARGO_TARGET_DIR)."
    out_of_scope:
      - "Distributed leasing across nodes (future holonic lease integration)."
  plan:
    steps:
      - "Reuse the existing slot-leasing implementation pattern from fac_review/model_pool.rs (RAII + jitter) to implement compute slots."
      - "Implement toolchain fingerprint derivation (rustc -Vv hash) for target pool namespace."
      - "Integrate slot acquisition + env setting into gates/warm/pipeline."
      - "Expose slot count override via env var (FAC_MAX_CONCURRENT_SLOTS)."
  definition_of_done:
    evidence_ids: []
    criteria:
      - "Concurrent invocations of warm/gates do not exceed configured slot count."
      - "Slots release on process exit even on failure."
      - "CARGO_TARGET_DIR is set by FAC to the slot target pool for all cargo-based gates (including bounded tests via env allowlist propagation)."
```

### TCK-00507 — Mandate nextest for all FAC test execution paths + enforce bounded test caps

```yaml
ticket_meta:
  schema_version: "2026-01-29"
  template_version: "2026-01-29"
  ticket:
    id: "TCK-00507"
    title: "Mandate nextest for all FAC test execution paths + enforce bounded test caps"
    status: "OPEN"
  binds:
    prd_id: "PRD-0009"
    rfc_id: "RFC-0007"
    requirements: []
    evidence_artifacts: []
  custody:
    agent_roles:
      - "AGENT_IMPLEMENTER"
    responsibility_domains:
      - "DOMAIN_RUNTIME"
      - "DOMAIN_SECURITY"
  dependencies:
    tickets: []
  scope:
    in_scope:
      - "Remove cargo-test fallback for FAC tests across all call paths (pipeline + local gates)."
      - "Update gate_attestation default test command to nextest (eliminate reliance on callers passing overrides correctly)."
      - "Enforce bounded test caps in code: reject timeout_seconds > 240 unless explicit unsafe override is set."
      - "Propagate NEXTEST_TEST_THREADS (and other required env) through run_bounded_tests.sh allowlist."
      - "Improve error messaging when nextest is missing: fail fast with actionable remediation (nix develop / install cargo-nextest)."
    out_of_scope:
      - "Changing nextest config semantics or profiles beyond concurrency defaults."
  plan:
    steps:
      - "Update evidence.rs: build_pipeline_test_command() returns nextest always; remove cargo test fallback."
      - "Update gates.rs: ensure non-bounded local gates still use nextest; do not silently fall back to cargo test."
      - "Update gate_attestation.rs: default 'test' gate command uses cargo nextest run ... (matching policy)."
      - "Update run_bounded_tests.sh allowlist to include NEXTEST_TEST_THREADS (+ any missing env required by new policy)."
      - "Add regression tests: verify that nextest is used; verify caps enforcement; verify attestation uses nextest command."
  definition_of_done:
    evidence_ids: []
    criteria:
      - "No FAC test run path uses cargo test."
      - "Bounded test timeout cannot be increased above 240s without explicit unsafe override."
      - "Bounded test runner sees NEXTEST_TEST_THREADS when set by FAC policy."
  notes:
    security: |
      This ticket is policy enforcement. The goal is to eliminate ambient-state ambiguity and
      prevent accidental host-destabilizing overrides.
```